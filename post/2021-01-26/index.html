<!doctype html><html lang=zh-cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><title>在AWS上使用EMR创建一个简单的数据湖（2） - 心之所向</title><meta name=renderer content="webkit"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta http-equiv=cache-control content="no-transform"><meta http-equiv=cache-control content="no-siteapp"><meta name=theme-color content="#f8f5ec"><meta name=msapplication-navbutton-color content="#f8f5ec"><meta name=apple-mobile-web-app-capable content="yes"><meta name=apple-mobile-web-app-status-bar-style content="#f8f5ec"><meta name=author content="Zhengguang Chen"><meta name=description content="接下来，我们就可以动手创建AWS上的各种资源了。Terraform走起~
创建S3存储 创建S3的代码很简单，只需要注意这么几点：
S3需要一个唯一的名字。不光是在自己的AWS账号上唯一哦，因为S3的名字是所谓Global Name，需要全球唯一 =_=! 偶尔还是要有一些安全意识的，比如ACL最好设成private 存储的数据量大了，我们就要考虑成本问题了。S3大致上有三级存储，Standard/Standard_IA/Glacier，性能和价格双双依次降低。在绝大多数情况下，我们只会频繁使用近期的数据。这样，我们可以把古老的数据挪到更便宜的存储上。虽然S3已经很便宜了，但是羊毛还是能薅就薅。 Terraform代码如下：
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 resource &amp;#34;aws_s3_bucket&amp;#34; &amp;#34;data&amp;#34; { bucket = &amp;#34;${var.company_name}-${var.team_name}-data-${var.environment}&amp;#34; acl = &amp;#34;private&amp;#34; tags = local.common.tags lifecycle_rule { id = &amp;#34;${var.company_name}-${var.team_name}-data-${var.environment}-rule&amp;#34; enabled = true transition { days = 60 storage_class = &amp;#34;STANDARD_IA&amp;#34; } transition { days = 365 storage_class = &amp;#34;GLACIER&amp;#34; } } } 我们还可以加点别的功能（所谓“来都来了”），比如当我们给S3中写入了新的数据的时候，我们想得到一个通知。之后利用这个通知，我们就可以驱动很多事情，比如EMR上面的处理任务，或者发邮件通知同事们数据已经准备好了。这个也不难，首先创建一个SNS消息队列，然后把安全性配置好就行了。走起~
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 // 创建SNS消息队列 resource &amp;#34;aws_sns_topic&amp;#34; &amp;#34;sns_s3_data_notification_queue&amp;#34; { name = &amp;#34;${var.team_name}-sns-s3-notification-${var.environment}&amp;#34; tags = local.common.tags } // 设置SNS，允许S3发送消息 data &amp;#34;aws_iam_policy_document&amp;#34; &amp;#34;sns_policy_doc&amp;#34; { statement { actions = [&amp;#34;SNS:Publish&amp;#34;] effect = &amp;#34;Allow&amp;#34; principals { type = &amp;#34;AWS&amp;#34; identifiers = [&amp;#34;*&amp;#34;] } resources = [&amp;#34;${aws_sns_topic.sns_s3_data_notification_queue.arn}&amp;#34;] condition { test = &amp;#34;ArnLike&amp;#34; variable = &amp;#34;aws:SourceArn&amp;#34; values = [&amp;#34;${aws_s3_bucket.data.arn}&amp;#34;] } } } resource &amp;#34;aws_sns_topic_policy&amp;#34; &amp;#34;default&amp;#34; { arn = &amp;#34;${aws_sns_topic.SNS_s3_notification.arn}&amp;#34; policy = &amp;#34;${data.aws_iam_policy_document.SNS_policy_doc.json}&amp;#34; } // 设置S3，发送ObjectCreated消息 resource &amp;#34;aws_s3_bucket_notification&amp;#34; &amp;#34;data-bucket-notification&amp;#34; { bucket = &amp;#34;${aws_s3_bucket.general_data.id}&amp;#34; topic { topic_arn = &amp;#34;${aws_sns_topic.SNS_s3_notification.arn}&amp;#34; events = [&amp;#34;s3:ObjectCreated:*&amp;#34;] } } 很好，从数据存储角度来说，这个S3基本够用了。
创建EMR集群 在我们的计划中，所有的ETL任务都是在同一个EMR集群上运行的。创建EMR还是比较麻烦的，主要是安全性的配置非常多。这也就是为什么有很多公司提供一键部署EMR集群的服务，虽然只是在AWS上包装了一层，但还能向用户再次收费的原因，毕竟省了很多事儿啊。不过我们一步一步来，先从创建一个简单的EMR集群开始。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 resource &amp;#34;aws_emr_cluster&amp;#34; &amp;#34;etl_cluster&amp;#34; { name = &amp;#34;${var.team_name}-etl-cluster-${var.environment}&amp;#34; tags = merge( local.common.tags, { useTag = &amp;#34;etl&amp;#34; } ) release_label = &amp;#34;emr-5.30.0&amp;#34; applications = [&amp;#34;Spark&amp;#34;] master_instance_group { instance_type = &amp;#34;m5.xlarge&amp;#34; } core_instance_group { instance_type = &amp;#34;m5.xlarge&amp;#34; instance_count = 5 name = &amp;#34;${var.team_name}-etl-cluster-core-instance-group-${var.environment}&amp;#34; } } 是的，就是这么简单。我们只装了一个软件，就是Spark，用来做计算。根据不同的需求，我们还可以安装Hadoop来做传统的MapReduce计算，或者Livy来做更好的Spark任务管理。具体需要装什么软件，各位看官可能比我还要熟悉，这里就不提了。我们在这个系列文章里只以Spark来举例。
运行一下这个Terraform脚本，各种关于安全性的狗屁倒灶的事情就接踵而来。首先，EMR可以理解为AWS帮我们管理一堆EC2机器。但是，EMR本身需要一定的权限来对机器进行添加、删除、监控、更改权限等等操作。这个叫做EMR服务角色（Service Role）。我们需要把这个角色创建出来，并且告诉我们的集群，使用这个角色来管理我们的集群机器。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 data &amp;#34;aws_iam_policy_document&amp;#34; &amp;#34;emr_service_assume_role&amp;#34; { statement { principals { type = &amp;#34;Service&amp;#34; identifiers = [ &amp;#34;elasticmapreduce.amazonaws.com&amp;#34;, &amp;#34;application-autoscaling.amazonaws.com&amp;#34; ] } actions = [&amp;#34;sts:AssumeRole&amp;#34;] } } resource &amp;#34;aws_iam_role&amp;#34; &amp;#34;emr_service_role&amp;#34; { name = &amp;#34;${var.team_name}-emr-service-role-${var.environment}&amp;#34; assume_role_policy = data.aws_iam_policy_document.emr_service_assume_role.json tags = local.common.tags path = &amp;#34;/${var.team_name}/&amp;#34; } resource &amp;#34;aws_iam_role_policy_attachment&amp;#34; &amp;#34;emr_service_role_policy_attachment&amp;#34; { role = aws_iam_role.emr_service_role.name policy_arn = &amp;#34;arn:aws:iam::aws:policy/service-role/AmazonElasticMapReduceRole&amp;#34; } 上面的这种代码如此常用，已经可以提取出来作为创建IAM角色的标准模板了，也就是先创建一个空白的角色，用AssumeRole策略告诉AWS谁可以代入这个角色。最后再把这个角色所具有的策略添加上去。这里，我们没有手动创建角色所具有的策略，而是使用了AWS自动创建的AmazonElasticMapReduceRole策略。有兴趣的人，或者公司的安全管理人员可以去看看这个策略里包含了哪些权限，保准你会感到心惊胆战，基本上能赋予的权限都包圆了。我们可不可以自己设定一个稍微弱一点的权限呢，能提升一点安全性就提升一点。答案是……不能。经过多次尝试，并且和AWS Tech Support各种亲切交流，我最终确认了，这个策略还是不要动为好。不过可以聊以自慰的是，这个角色只会被AWS自己使用，只能用人不疑了。
这样，我们就可以告诉EMR使用我们刚刚创建的IAM角色了。
1 2 3 4 5 resource &amp;#34;aws_emr_cluster&amp;#34; &amp;#34;etl_cluster&amp;#34; { ... service_role = aws_iam_role.emr_service_role.arn } 接下来，我们要配置我们的EMR集群，使得当任务较多的时候，我们的集群可以自动添加更多的机器，而当任务较少的时候，集群里的机器也会自动变少。这个过程最好越快越好，这样我们在拥有足够多的机器来完成任务的同时，也能充分省钱。小门小户的，要精打细算。这里，我们需要创建一个支持自动伸缩（Auto Scaling）的角色来供EMR使用。是的，我们要创建新的角色而不能重用之前的服务角色，因为赋予的权限是不同的。所幸我们不需要自己去研究哪些权限是必要的，因为AWS再一次自动帮我们创建了包含必要权限的策略。之后，我们需要创建一个EMR集群的自动伸缩策略，告诉AWS我们最少需要保持多少机器，最多允许多少机器（否则一个不小心，分分钟破产的节奏）。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 resource &amp;#34;aws_iam_role&amp;#34; &amp;#34;emr_autoscaling_role&amp;#34; { name = &amp;#34;${var.team_name}-emr-autoscaling-role-${var.environment}&amp;#34; assume_role_policy = data.aws_iam_policy_document.emr_service_assume_role.json tags = local.common.tags path = &amp;#34;/${var.team_name}/&amp;#34; } resource &amp;#34;aws_iam_role_policy_attachment&amp;#34; &amp;#34;emr_autoscaling_role_policy_attachment&amp;#34; { role = aws_iam_role.emr_autoscaling_role.name policy_arn = &amp;#34;arn:aws:iam::aws:policy/service-role/AmazonElasticMapReduceforAutoScalingRole&amp;#34; } resource &amp;#34;aws_emr_cluster&amp;#34; &amp;#34;etl_cluster&amp;#34; { ... autoscaling_role = aws_iam_role.emr_autoscaling_role.arn } resource &amp;#34;aws_emr_managed_scaling_policy&amp;#34; &amp;#34;emr_scaling_policy&amp;#34; { cluster_id = aws_emr_cluster.etl_cluster.id compute_limits { unit_type = &amp;#34;Instances&amp;#34; minimum_capacity_units = 5 maximum_capacity_units = 200 maximum_ondemand_capacity_units = 40 maximum_core_capacity_units = 10 } } 最后，我们的EMR集群需要一个地方来存储日志。EMR可以在本机存日志，但是我们真的不想每次都冲上集群的机器上去看日志，而是想在网页界面上直接看到任务的运行状况，并且当EMR集群由于某种原因挂掉的时候（这是日志文件这辈子最重要的时刻），我们还是可以看到日志，并得知集群最后的遗言。总之，我们希望EMR集群的日志保存在一个EMR之外的地方。是的，你猜对了，S3走起。我们另外创建一个S3存储日志，并配置我们的EMR集群持续写入。由于S3只能写入一个一个完整的对象，而不能持续给对象尾部添加内容，为了避免产生大量的小对象，EMR内部会有缓存机制，默认每5分钟才会写入一次S3。这会导致S3里的日志有时会滞后一些。不过为了能方便的看到日志，我们只能捏着鼻子忍了。最后，日志终究只是日志而已，为了节省空间，三十天后我们就可以自动删除日志了，这个在S3上配置也很方便。
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 resource &amp;#34;aws_s3_bucket&amp;#34; &amp;#34;emr_log&amp;#34; { bucket = &amp;#34;${var.company_name}-${var.team_name}-emr-log-${var.environment}&amp;#34; acl = &amp;#34;private&amp;#34; tags = local.common.tags lifecycle_rule { id = &amp;#34;${var.company_name}-${var.team_name}-emr-log-${var.environment}-rule&amp;#34; enabled = true expiration { days = 30 } } } resource &amp;#34;aws_emr_cluster&amp;#34; &amp;#34;etl_cluster&amp;#34; { ... log_uri = &amp;#34;s3n://${aws_s3_bucket.emr_log.id}/&amp;#34; } "><meta name=keywords content="个人,博客,技术"><meta name=generator content="Hugo 0.107.0 with theme even"><link rel=canonical href=https://blog.cerrorism.com/post/2021-01-26/><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/manifest.json><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link href=/sass/main.min.f92fd13721ddf72129410fd8250e73152cc6f2438082b6c0208dc24ee7c13fc4.css rel=stylesheet><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin=anonymous><meta property="og:title" content="在AWS上使用EMR创建一个简单的数据湖（2）"><meta property="og:description" content="接下来，我们就可以动手创建AWS上的各种资源了。Terraform走起~
创建S3存储
创建S3的代码很简单，只需要注意这么几点：

S3需要一个唯一的名字。不光是在自己的AWS账号上唯一哦，因为S3的名字是所谓Global Name，需要全球唯一 =_=!
偶尔还是要有一些安全意识的，比如ACL最好设成private
存储的数据量大了，我们就要考虑成本问题了。S3大致上有三级存储，Standard/Standard_IA/Glacier，性能和价格双双依次降低。在绝大多数情况下，我们只会频繁使用近期的数据。这样，我们可以把古老的数据挪到更便宜的存储上。虽然S3已经很便宜了，但是羊毛还是能薅就薅。

Terraform代码如下：


 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18


resource &#34;aws_s3_bucket&#34; &#34;data&#34; {
  bucket = &#34;${var.company_name}-${var.team_name}-data-${var.environment}&#34;
  acl    = &#34;private&#34;
  tags   = local.common.tags

  lifecycle_rule {
    id      = &#34;${var.company_name}-${var.team_name}-data-${var.environment}-rule&#34;
    enabled = true
    transition {
      days          = 60
      storage_class = &#34;STANDARD_IA&#34;
    }
    transition {
      days          = 365
      storage_class = &#34;GLACIER&#34;
    }
  }
}


我们还可以加点别的功能（所谓“来都来了”），比如当我们给S3中写入了新的数据的时候，我们想得到一个通知。之后利用这个通知，我们就可以驱动很多事情，比如EMR上面的处理任务，或者发邮件通知同事们数据已经准备好了。这个也不难，首先创建一个SNS消息队列，然后把安全性配置好就行了。走起~


 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38



// 创建SNS消息队列
resource &#34;aws_sns_topic&#34; &#34;sns_s3_data_notification_queue&#34; {
  name = &#34;${var.team_name}-sns-s3-notification-${var.environment}&#34;
  tags = local.common.tags
}

// 设置SNS，允许S3发送消息
data &#34;aws_iam_policy_document&#34; &#34;sns_policy_doc&#34; {
    statement {
        actions = [&#34;SNS:Publish&#34;]
        effect = &#34;Allow&#34;
        principals {
            type        = &#34;AWS&#34;
            identifiers = [&#34;*&#34;]
        }
        resources = [&#34;${aws_sns_topic.sns_s3_data_notification_queue.arn}&#34;]
        condition {
            test     = &#34;ArnLike&#34;
            variable = &#34;aws:SourceArn&#34;
            values = [&#34;${aws_s3_bucket.data.arn}&#34;]
        }
    }
}

resource &#34;aws_sns_topic_policy&#34; &#34;default&#34; {
    arn = &#34;${aws_sns_topic.SNS_s3_notification.arn}&#34;
    policy = &#34;${data.aws_iam_policy_document.SNS_policy_doc.json}&#34;
}

// 设置S3，发送ObjectCreated消息
resource &#34;aws_s3_bucket_notification&#34; &#34;data-bucket-notification&#34; {
  bucket = &#34;${aws_s3_bucket.general_data.id}&#34;
  topic {
    topic_arn = &#34;${aws_sns_topic.SNS_s3_notification.arn}&#34;
    events = [&#34;s3:ObjectCreated:*&#34;]
  }
}


很好，从数据存储角度来说，这个S3基本够用了。
创建EMR集群
在我们的计划中，所有的ETL任务都是在同一个EMR集群上运行的。创建EMR还是比较麻烦的，主要是安全性的配置非常多。这也就是为什么有很多公司提供一键部署EMR集群的服务，虽然只是在AWS上包装了一层，但还能向用户再次收费的原因，毕竟省了很多事儿啊。不过我们一步一步来，先从创建一个简单的EMR集群开始。


 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21


resource &#34;aws_emr_cluster&#34; &#34;etl_cluster&#34; {
  name          = &#34;${var.team_name}-etl-cluster-${var.environment}&#34;
  tags          = merge( local.common.tags,
                        {
                          useTag = &#34;etl&#34;
                        }
                        )

  release_label = &#34;emr-5.30.0&#34;
  applications  = [&#34;Spark&#34;]

  master_instance_group {
    instance_type = &#34;m5.xlarge&#34;
  }

  core_instance_group {
    instance_type  = &#34;m5.xlarge&#34;
    instance_count = 5
    name           = &#34;${var.team_name}-etl-cluster-core-instance-group-${var.environment}&#34;
  }
}


是的，就是这么简单。我们只装了一个软件，就是Spark，用来做计算。根据不同的需求，我们还可以安装Hadoop来做传统的MapReduce计算，或者Livy来做更好的Spark任务管理。具体需要装什么软件，各位看官可能比我还要熟悉，这里就不提了。我们在这个系列文章里只以Spark来举例。
运行一下这个Terraform脚本，各种关于安全性的狗屁倒灶的事情就接踵而来。首先，EMR可以理解为AWS帮我们管理一堆EC2机器。但是，EMR本身需要一定的权限来对机器进行添加、删除、监控、更改权限等等操作。这个叫做EMR服务角色（Service Role）。我们需要把这个角色创建出来，并且告诉我们的集群，使用这个角色来管理我们的集群机器。


 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24


data &#34;aws_iam_policy_document&#34; &#34;emr_service_assume_role&#34; {
  statement {
    principals {
      type        = &#34;Service&#34;
      identifiers = [
        &#34;elasticmapreduce.amazonaws.com&#34;,
        &#34;application-autoscaling.amazonaws.com&#34;
      ]
    }
    actions = [&#34;sts:AssumeRole&#34;]
  }
}

resource &#34;aws_iam_role&#34; &#34;emr_service_role&#34; {
  name               = &#34;${var.team_name}-emr-service-role-${var.environment}&#34;
  assume_role_policy = data.aws_iam_policy_document.emr_service_assume_role.json
  tags               = local.common.tags
  path               = &#34;/${var.team_name}/&#34;
}

resource &#34;aws_iam_role_policy_attachment&#34; &#34;emr_service_role_policy_attachment&#34; {
  role       = aws_iam_role.emr_service_role.name
  policy_arn = &#34;arn:aws:iam::aws:policy/service-role/AmazonElasticMapReduceRole&#34;
}


上面的这种代码如此常用，已经可以提取出来作为创建IAM角色的标准模板了，也就是先创建一个空白的角色，用AssumeRole策略告诉AWS谁可以代入这个角色。最后再把这个角色所具有的策略添加上去。这里，我们没有手动创建角色所具有的策略，而是使用了AWS自动创建的AmazonElasticMapReduceRole策略。有兴趣的人，或者公司的安全管理人员可以去看看这个策略里包含了哪些权限，保准你会感到心惊胆战，基本上能赋予的权限都包圆了。我们可不可以自己设定一个稍微弱一点的权限呢，能提升一点安全性就提升一点。答案是……不能。经过多次尝试，并且和AWS Tech Support各种亲切交流，我最终确认了，这个策略还是不要动为好。不过可以聊以自慰的是，这个角色只会被AWS自己使用，只能用人不疑了。
这样，我们就可以告诉EMR使用我们刚刚创建的IAM角色了。


1
2
3
4
5


resource &#34;aws_emr_cluster&#34; &#34;etl_cluster&#34; {
  ...

  service_role     = aws_iam_role.emr_service_role.arn
}


接下来，我们要配置我们的EMR集群，使得当任务较多的时候，我们的集群可以自动添加更多的机器，而当任务较少的时候，集群里的机器也会自动变少。这个过程最好越快越好，这样我们在拥有足够多的机器来完成任务的同时，也能充分省钱。小门小户的，要精打细算。这里，我们需要创建一个支持自动伸缩（Auto Scaling）的角色来供EMR使用。是的，我们要创建新的角色而不能重用之前的服务角色，因为赋予的权限是不同的。所幸我们不需要自己去研究哪些权限是必要的，因为AWS再一次自动帮我们创建了包含必要权限的策略。之后，我们需要创建一个EMR集群的自动伸缩策略，告诉AWS我们最少需要保持多少机器，最多允许多少机器（否则一个不小心，分分钟破产的节奏）。


 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28


resource &#34;aws_iam_role&#34; &#34;emr_autoscaling_role&#34; {
  name               = &#34;${var.team_name}-emr-autoscaling-role-${var.environment}&#34;
  assume_role_policy = data.aws_iam_policy_document.emr_service_assume_role.json
  tags               = local.common.tags
  path               = &#34;/${var.team_name}/&#34;
}

resource &#34;aws_iam_role_policy_attachment&#34; &#34;emr_autoscaling_role_policy_attachment&#34; {
  role       = aws_iam_role.emr_autoscaling_role.name
  policy_arn = &#34;arn:aws:iam::aws:policy/service-role/AmazonElasticMapReduceforAutoScalingRole&#34;
}

resource &#34;aws_emr_cluster&#34; &#34;etl_cluster&#34; {
  ...

  autoscaling_role = aws_iam_role.emr_autoscaling_role.arn
}

resource &#34;aws_emr_managed_scaling_policy&#34; &#34;emr_scaling_policy&#34; {
  cluster_id = aws_emr_cluster.etl_cluster.id
  compute_limits {
    unit_type                       = &#34;Instances&#34;
    minimum_capacity_units          = 5
    maximum_capacity_units          = 200
    maximum_ondemand_capacity_units = 40
    maximum_core_capacity_units     = 10
  }
}


最后，我们的EMR集群需要一个地方来存储日志。EMR可以在本机存日志，但是我们真的不想每次都冲上集群的机器上去看日志，而是想在网页界面上直接看到任务的运行状况，并且当EMR集群由于某种原因挂掉的时候（这是日志文件这辈子最重要的时刻），我们还是可以看到日志，并得知集群最后的遗言。总之，我们希望EMR集群的日志保存在一个EMR之外的地方。是的，你猜对了，S3走起。我们另外创建一个S3存储日志，并配置我们的EMR集群持续写入。由于S3只能写入一个一个完整的对象，而不能持续给对象尾部添加内容，为了避免产生大量的小对象，EMR内部会有缓存机制，默认每5分钟才会写入一次S3。这会导致S3里的日志有时会滞后一些。不过为了能方便的看到日志，我们只能捏着鼻子忍了。最后，日志终究只是日志而已，为了节省空间，三十天后我们就可以自动删除日志了，这个在S3上配置也很方便。


 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19


resource &#34;aws_s3_bucket&#34; &#34;emr_log&#34; {
  bucket = &#34;${var.company_name}-${var.team_name}-emr-log-${var.environment}&#34;
  acl    = &#34;private&#34;
  tags   = local.common.tags

  lifecycle_rule {
    id      = &#34;${var.company_name}-${var.team_name}-emr-log-${var.environment}-rule&#34;
    enabled = true
    expiration {
      days = 30
    }
  }
}

resource &#34;aws_emr_cluster&#34; &#34;etl_cluster&#34; {
  ...

  log_uri          = &#34;s3n://${aws_s3_bucket.emr_log.id}/&#34;
}


"><meta property="og:type" content="article"><meta property="og:url" content="https://blog.cerrorism.com/post/2021-01-26/"><meta property="article:section" content="post"><meta property="article:published_time" content="2021-01-26T10:46:27-08:00"><meta property="article:modified_time" content="2021-01-26T10:46:27-08:00"><meta itemprop=name content="在AWS上使用EMR创建一个简单的数据湖（2）"><meta itemprop=description content="接下来，我们就可以动手创建AWS上的各种资源了。Terraform走起~
创建S3存储
创建S3的代码很简单，只需要注意这么几点：

S3需要一个唯一的名字。不光是在自己的AWS账号上唯一哦，因为S3的名字是所谓Global Name，需要全球唯一 =_=!
偶尔还是要有一些安全意识的，比如ACL最好设成private
存储的数据量大了，我们就要考虑成本问题了。S3大致上有三级存储，Standard/Standard_IA/Glacier，性能和价格双双依次降低。在绝大多数情况下，我们只会频繁使用近期的数据。这样，我们可以把古老的数据挪到更便宜的存储上。虽然S3已经很便宜了，但是羊毛还是能薅就薅。

Terraform代码如下：


 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18


resource &#34;aws_s3_bucket&#34; &#34;data&#34; {
  bucket = &#34;${var.company_name}-${var.team_name}-data-${var.environment}&#34;
  acl    = &#34;private&#34;
  tags   = local.common.tags

  lifecycle_rule {
    id      = &#34;${var.company_name}-${var.team_name}-data-${var.environment}-rule&#34;
    enabled = true
    transition {
      days          = 60
      storage_class = &#34;STANDARD_IA&#34;
    }
    transition {
      days          = 365
      storage_class = &#34;GLACIER&#34;
    }
  }
}


我们还可以加点别的功能（所谓“来都来了”），比如当我们给S3中写入了新的数据的时候，我们想得到一个通知。之后利用这个通知，我们就可以驱动很多事情，比如EMR上面的处理任务，或者发邮件通知同事们数据已经准备好了。这个也不难，首先创建一个SNS消息队列，然后把安全性配置好就行了。走起~


 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38



// 创建SNS消息队列
resource &#34;aws_sns_topic&#34; &#34;sns_s3_data_notification_queue&#34; {
  name = &#34;${var.team_name}-sns-s3-notification-${var.environment}&#34;
  tags = local.common.tags
}

// 设置SNS，允许S3发送消息
data &#34;aws_iam_policy_document&#34; &#34;sns_policy_doc&#34; {
    statement {
        actions = [&#34;SNS:Publish&#34;]
        effect = &#34;Allow&#34;
        principals {
            type        = &#34;AWS&#34;
            identifiers = [&#34;*&#34;]
        }
        resources = [&#34;${aws_sns_topic.sns_s3_data_notification_queue.arn}&#34;]
        condition {
            test     = &#34;ArnLike&#34;
            variable = &#34;aws:SourceArn&#34;
            values = [&#34;${aws_s3_bucket.data.arn}&#34;]
        }
    }
}

resource &#34;aws_sns_topic_policy&#34; &#34;default&#34; {
    arn = &#34;${aws_sns_topic.SNS_s3_notification.arn}&#34;
    policy = &#34;${data.aws_iam_policy_document.SNS_policy_doc.json}&#34;
}

// 设置S3，发送ObjectCreated消息
resource &#34;aws_s3_bucket_notification&#34; &#34;data-bucket-notification&#34; {
  bucket = &#34;${aws_s3_bucket.general_data.id}&#34;
  topic {
    topic_arn = &#34;${aws_sns_topic.SNS_s3_notification.arn}&#34;
    events = [&#34;s3:ObjectCreated:*&#34;]
  }
}


很好，从数据存储角度来说，这个S3基本够用了。
创建EMR集群
在我们的计划中，所有的ETL任务都是在同一个EMR集群上运行的。创建EMR还是比较麻烦的，主要是安全性的配置非常多。这也就是为什么有很多公司提供一键部署EMR集群的服务，虽然只是在AWS上包装了一层，但还能向用户再次收费的原因，毕竟省了很多事儿啊。不过我们一步一步来，先从创建一个简单的EMR集群开始。


 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21


resource &#34;aws_emr_cluster&#34; &#34;etl_cluster&#34; {
  name          = &#34;${var.team_name}-etl-cluster-${var.environment}&#34;
  tags          = merge( local.common.tags,
                        {
                          useTag = &#34;etl&#34;
                        }
                        )

  release_label = &#34;emr-5.30.0&#34;
  applications  = [&#34;Spark&#34;]

  master_instance_group {
    instance_type = &#34;m5.xlarge&#34;
  }

  core_instance_group {
    instance_type  = &#34;m5.xlarge&#34;
    instance_count = 5
    name           = &#34;${var.team_name}-etl-cluster-core-instance-group-${var.environment}&#34;
  }
}


是的，就是这么简单。我们只装了一个软件，就是Spark，用来做计算。根据不同的需求，我们还可以安装Hadoop来做传统的MapReduce计算，或者Livy来做更好的Spark任务管理。具体需要装什么软件，各位看官可能比我还要熟悉，这里就不提了。我们在这个系列文章里只以Spark来举例。
运行一下这个Terraform脚本，各种关于安全性的狗屁倒灶的事情就接踵而来。首先，EMR可以理解为AWS帮我们管理一堆EC2机器。但是，EMR本身需要一定的权限来对机器进行添加、删除、监控、更改权限等等操作。这个叫做EMR服务角色（Service Role）。我们需要把这个角色创建出来，并且告诉我们的集群，使用这个角色来管理我们的集群机器。


 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24


data &#34;aws_iam_policy_document&#34; &#34;emr_service_assume_role&#34; {
  statement {
    principals {
      type        = &#34;Service&#34;
      identifiers = [
        &#34;elasticmapreduce.amazonaws.com&#34;,
        &#34;application-autoscaling.amazonaws.com&#34;
      ]
    }
    actions = [&#34;sts:AssumeRole&#34;]
  }
}

resource &#34;aws_iam_role&#34; &#34;emr_service_role&#34; {
  name               = &#34;${var.team_name}-emr-service-role-${var.environment}&#34;
  assume_role_policy = data.aws_iam_policy_document.emr_service_assume_role.json
  tags               = local.common.tags
  path               = &#34;/${var.team_name}/&#34;
}

resource &#34;aws_iam_role_policy_attachment&#34; &#34;emr_service_role_policy_attachment&#34; {
  role       = aws_iam_role.emr_service_role.name
  policy_arn = &#34;arn:aws:iam::aws:policy/service-role/AmazonElasticMapReduceRole&#34;
}


上面的这种代码如此常用，已经可以提取出来作为创建IAM角色的标准模板了，也就是先创建一个空白的角色，用AssumeRole策略告诉AWS谁可以代入这个角色。最后再把这个角色所具有的策略添加上去。这里，我们没有手动创建角色所具有的策略，而是使用了AWS自动创建的AmazonElasticMapReduceRole策略。有兴趣的人，或者公司的安全管理人员可以去看看这个策略里包含了哪些权限，保准你会感到心惊胆战，基本上能赋予的权限都包圆了。我们可不可以自己设定一个稍微弱一点的权限呢，能提升一点安全性就提升一点。答案是……不能。经过多次尝试，并且和AWS Tech Support各种亲切交流，我最终确认了，这个策略还是不要动为好。不过可以聊以自慰的是，这个角色只会被AWS自己使用，只能用人不疑了。
这样，我们就可以告诉EMR使用我们刚刚创建的IAM角色了。


1
2
3
4
5


resource &#34;aws_emr_cluster&#34; &#34;etl_cluster&#34; {
  ...

  service_role     = aws_iam_role.emr_service_role.arn
}


接下来，我们要配置我们的EMR集群，使得当任务较多的时候，我们的集群可以自动添加更多的机器，而当任务较少的时候，集群里的机器也会自动变少。这个过程最好越快越好，这样我们在拥有足够多的机器来完成任务的同时，也能充分省钱。小门小户的，要精打细算。这里，我们需要创建一个支持自动伸缩（Auto Scaling）的角色来供EMR使用。是的，我们要创建新的角色而不能重用之前的服务角色，因为赋予的权限是不同的。所幸我们不需要自己去研究哪些权限是必要的，因为AWS再一次自动帮我们创建了包含必要权限的策略。之后，我们需要创建一个EMR集群的自动伸缩策略，告诉AWS我们最少需要保持多少机器，最多允许多少机器（否则一个不小心，分分钟破产的节奏）。


 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28


resource &#34;aws_iam_role&#34; &#34;emr_autoscaling_role&#34; {
  name               = &#34;${var.team_name}-emr-autoscaling-role-${var.environment}&#34;
  assume_role_policy = data.aws_iam_policy_document.emr_service_assume_role.json
  tags               = local.common.tags
  path               = &#34;/${var.team_name}/&#34;
}

resource &#34;aws_iam_role_policy_attachment&#34; &#34;emr_autoscaling_role_policy_attachment&#34; {
  role       = aws_iam_role.emr_autoscaling_role.name
  policy_arn = &#34;arn:aws:iam::aws:policy/service-role/AmazonElasticMapReduceforAutoScalingRole&#34;
}

resource &#34;aws_emr_cluster&#34; &#34;etl_cluster&#34; {
  ...

  autoscaling_role = aws_iam_role.emr_autoscaling_role.arn
}

resource &#34;aws_emr_managed_scaling_policy&#34; &#34;emr_scaling_policy&#34; {
  cluster_id = aws_emr_cluster.etl_cluster.id
  compute_limits {
    unit_type                       = &#34;Instances&#34;
    minimum_capacity_units          = 5
    maximum_capacity_units          = 200
    maximum_ondemand_capacity_units = 40
    maximum_core_capacity_units     = 10
  }
}


最后，我们的EMR集群需要一个地方来存储日志。EMR可以在本机存日志，但是我们真的不想每次都冲上集群的机器上去看日志，而是想在网页界面上直接看到任务的运行状况，并且当EMR集群由于某种原因挂掉的时候（这是日志文件这辈子最重要的时刻），我们还是可以看到日志，并得知集群最后的遗言。总之，我们希望EMR集群的日志保存在一个EMR之外的地方。是的，你猜对了，S3走起。我们另外创建一个S3存储日志，并配置我们的EMR集群持续写入。由于S3只能写入一个一个完整的对象，而不能持续给对象尾部添加内容，为了避免产生大量的小对象，EMR内部会有缓存机制，默认每5分钟才会写入一次S3。这会导致S3里的日志有时会滞后一些。不过为了能方便的看到日志，我们只能捏着鼻子忍了。最后，日志终究只是日志而已，为了节省空间，三十天后我们就可以自动删除日志了，这个在S3上配置也很方便。


 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19


resource &#34;aws_s3_bucket&#34; &#34;emr_log&#34; {
  bucket = &#34;${var.company_name}-${var.team_name}-emr-log-${var.environment}&#34;
  acl    = &#34;private&#34;
  tags   = local.common.tags

  lifecycle_rule {
    id      = &#34;${var.company_name}-${var.team_name}-emr-log-${var.environment}-rule&#34;
    enabled = true
    expiration {
      days = 30
    }
  }
}

resource &#34;aws_emr_cluster&#34; &#34;etl_cluster&#34; {
  ...

  log_uri          = &#34;s3n://${aws_s3_bucket.emr_log.id}/&#34;
}


"><meta itemprop=datePublished content="2021-01-26T10:46:27-08:00"><meta itemprop=dateModified content="2021-01-26T10:46:27-08:00"><meta itemprop=wordCount content="2530"><meta itemprop=keywords content><meta name=twitter:card content="summary"><meta name=twitter:title content="在AWS上使用EMR创建一个简单的数据湖（2）"><meta name=twitter:description content="接下来，我们就可以动手创建AWS上的各种资源了。Terraform走起~
创建S3存储
创建S3的代码很简单，只需要注意这么几点：

S3需要一个唯一的名字。不光是在自己的AWS账号上唯一哦，因为S3的名字是所谓Global Name，需要全球唯一 =_=!
偶尔还是要有一些安全意识的，比如ACL最好设成private
存储的数据量大了，我们就要考虑成本问题了。S3大致上有三级存储，Standard/Standard_IA/Glacier，性能和价格双双依次降低。在绝大多数情况下，我们只会频繁使用近期的数据。这样，我们可以把古老的数据挪到更便宜的存储上。虽然S3已经很便宜了，但是羊毛还是能薅就薅。

Terraform代码如下：


 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18


resource &#34;aws_s3_bucket&#34; &#34;data&#34; {
  bucket = &#34;${var.company_name}-${var.team_name}-data-${var.environment}&#34;
  acl    = &#34;private&#34;
  tags   = local.common.tags

  lifecycle_rule {
    id      = &#34;${var.company_name}-${var.team_name}-data-${var.environment}-rule&#34;
    enabled = true
    transition {
      days          = 60
      storage_class = &#34;STANDARD_IA&#34;
    }
    transition {
      days          = 365
      storage_class = &#34;GLACIER&#34;
    }
  }
}


我们还可以加点别的功能（所谓“来都来了”），比如当我们给S3中写入了新的数据的时候，我们想得到一个通知。之后利用这个通知，我们就可以驱动很多事情，比如EMR上面的处理任务，或者发邮件通知同事们数据已经准备好了。这个也不难，首先创建一个SNS消息队列，然后把安全性配置好就行了。走起~


 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38



// 创建SNS消息队列
resource &#34;aws_sns_topic&#34; &#34;sns_s3_data_notification_queue&#34; {
  name = &#34;${var.team_name}-sns-s3-notification-${var.environment}&#34;
  tags = local.common.tags
}

// 设置SNS，允许S3发送消息
data &#34;aws_iam_policy_document&#34; &#34;sns_policy_doc&#34; {
    statement {
        actions = [&#34;SNS:Publish&#34;]
        effect = &#34;Allow&#34;
        principals {
            type        = &#34;AWS&#34;
            identifiers = [&#34;*&#34;]
        }
        resources = [&#34;${aws_sns_topic.sns_s3_data_notification_queue.arn}&#34;]
        condition {
            test     = &#34;ArnLike&#34;
            variable = &#34;aws:SourceArn&#34;
            values = [&#34;${aws_s3_bucket.data.arn}&#34;]
        }
    }
}

resource &#34;aws_sns_topic_policy&#34; &#34;default&#34; {
    arn = &#34;${aws_sns_topic.SNS_s3_notification.arn}&#34;
    policy = &#34;${data.aws_iam_policy_document.SNS_policy_doc.json}&#34;
}

// 设置S3，发送ObjectCreated消息
resource &#34;aws_s3_bucket_notification&#34; &#34;data-bucket-notification&#34; {
  bucket = &#34;${aws_s3_bucket.general_data.id}&#34;
  topic {
    topic_arn = &#34;${aws_sns_topic.SNS_s3_notification.arn}&#34;
    events = [&#34;s3:ObjectCreated:*&#34;]
  }
}


很好，从数据存储角度来说，这个S3基本够用了。
创建EMR集群
在我们的计划中，所有的ETL任务都是在同一个EMR集群上运行的。创建EMR还是比较麻烦的，主要是安全性的配置非常多。这也就是为什么有很多公司提供一键部署EMR集群的服务，虽然只是在AWS上包装了一层，但还能向用户再次收费的原因，毕竟省了很多事儿啊。不过我们一步一步来，先从创建一个简单的EMR集群开始。


 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21


resource &#34;aws_emr_cluster&#34; &#34;etl_cluster&#34; {
  name          = &#34;${var.team_name}-etl-cluster-${var.environment}&#34;
  tags          = merge( local.common.tags,
                        {
                          useTag = &#34;etl&#34;
                        }
                        )

  release_label = &#34;emr-5.30.0&#34;
  applications  = [&#34;Spark&#34;]

  master_instance_group {
    instance_type = &#34;m5.xlarge&#34;
  }

  core_instance_group {
    instance_type  = &#34;m5.xlarge&#34;
    instance_count = 5
    name           = &#34;${var.team_name}-etl-cluster-core-instance-group-${var.environment}&#34;
  }
}


是的，就是这么简单。我们只装了一个软件，就是Spark，用来做计算。根据不同的需求，我们还可以安装Hadoop来做传统的MapReduce计算，或者Livy来做更好的Spark任务管理。具体需要装什么软件，各位看官可能比我还要熟悉，这里就不提了。我们在这个系列文章里只以Spark来举例。
运行一下这个Terraform脚本，各种关于安全性的狗屁倒灶的事情就接踵而来。首先，EMR可以理解为AWS帮我们管理一堆EC2机器。但是，EMR本身需要一定的权限来对机器进行添加、删除、监控、更改权限等等操作。这个叫做EMR服务角色（Service Role）。我们需要把这个角色创建出来，并且告诉我们的集群，使用这个角色来管理我们的集群机器。


 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24


data &#34;aws_iam_policy_document&#34; &#34;emr_service_assume_role&#34; {
  statement {
    principals {
      type        = &#34;Service&#34;
      identifiers = [
        &#34;elasticmapreduce.amazonaws.com&#34;,
        &#34;application-autoscaling.amazonaws.com&#34;
      ]
    }
    actions = [&#34;sts:AssumeRole&#34;]
  }
}

resource &#34;aws_iam_role&#34; &#34;emr_service_role&#34; {
  name               = &#34;${var.team_name}-emr-service-role-${var.environment}&#34;
  assume_role_policy = data.aws_iam_policy_document.emr_service_assume_role.json
  tags               = local.common.tags
  path               = &#34;/${var.team_name}/&#34;
}

resource &#34;aws_iam_role_policy_attachment&#34; &#34;emr_service_role_policy_attachment&#34; {
  role       = aws_iam_role.emr_service_role.name
  policy_arn = &#34;arn:aws:iam::aws:policy/service-role/AmazonElasticMapReduceRole&#34;
}


上面的这种代码如此常用，已经可以提取出来作为创建IAM角色的标准模板了，也就是先创建一个空白的角色，用AssumeRole策略告诉AWS谁可以代入这个角色。最后再把这个角色所具有的策略添加上去。这里，我们没有手动创建角色所具有的策略，而是使用了AWS自动创建的AmazonElasticMapReduceRole策略。有兴趣的人，或者公司的安全管理人员可以去看看这个策略里包含了哪些权限，保准你会感到心惊胆战，基本上能赋予的权限都包圆了。我们可不可以自己设定一个稍微弱一点的权限呢，能提升一点安全性就提升一点。答案是……不能。经过多次尝试，并且和AWS Tech Support各种亲切交流，我最终确认了，这个策略还是不要动为好。不过可以聊以自慰的是，这个角色只会被AWS自己使用，只能用人不疑了。
这样，我们就可以告诉EMR使用我们刚刚创建的IAM角色了。


1
2
3
4
5


resource &#34;aws_emr_cluster&#34; &#34;etl_cluster&#34; {
  ...

  service_role     = aws_iam_role.emr_service_role.arn
}


接下来，我们要配置我们的EMR集群，使得当任务较多的时候，我们的集群可以自动添加更多的机器，而当任务较少的时候，集群里的机器也会自动变少。这个过程最好越快越好，这样我们在拥有足够多的机器来完成任务的同时，也能充分省钱。小门小户的，要精打细算。这里，我们需要创建一个支持自动伸缩（Auto Scaling）的角色来供EMR使用。是的，我们要创建新的角色而不能重用之前的服务角色，因为赋予的权限是不同的。所幸我们不需要自己去研究哪些权限是必要的，因为AWS再一次自动帮我们创建了包含必要权限的策略。之后，我们需要创建一个EMR集群的自动伸缩策略，告诉AWS我们最少需要保持多少机器，最多允许多少机器（否则一个不小心，分分钟破产的节奏）。


 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28


resource &#34;aws_iam_role&#34; &#34;emr_autoscaling_role&#34; {
  name               = &#34;${var.team_name}-emr-autoscaling-role-${var.environment}&#34;
  assume_role_policy = data.aws_iam_policy_document.emr_service_assume_role.json
  tags               = local.common.tags
  path               = &#34;/${var.team_name}/&#34;
}

resource &#34;aws_iam_role_policy_attachment&#34; &#34;emr_autoscaling_role_policy_attachment&#34; {
  role       = aws_iam_role.emr_autoscaling_role.name
  policy_arn = &#34;arn:aws:iam::aws:policy/service-role/AmazonElasticMapReduceforAutoScalingRole&#34;
}

resource &#34;aws_emr_cluster&#34; &#34;etl_cluster&#34; {
  ...

  autoscaling_role = aws_iam_role.emr_autoscaling_role.arn
}

resource &#34;aws_emr_managed_scaling_policy&#34; &#34;emr_scaling_policy&#34; {
  cluster_id = aws_emr_cluster.etl_cluster.id
  compute_limits {
    unit_type                       = &#34;Instances&#34;
    minimum_capacity_units          = 5
    maximum_capacity_units          = 200
    maximum_ondemand_capacity_units = 40
    maximum_core_capacity_units     = 10
  }
}


最后，我们的EMR集群需要一个地方来存储日志。EMR可以在本机存日志，但是我们真的不想每次都冲上集群的机器上去看日志，而是想在网页界面上直接看到任务的运行状况，并且当EMR集群由于某种原因挂掉的时候（这是日志文件这辈子最重要的时刻），我们还是可以看到日志，并得知集群最后的遗言。总之，我们希望EMR集群的日志保存在一个EMR之外的地方。是的，你猜对了，S3走起。我们另外创建一个S3存储日志，并配置我们的EMR集群持续写入。由于S3只能写入一个一个完整的对象，而不能持续给对象尾部添加内容，为了避免产生大量的小对象，EMR内部会有缓存机制，默认每5分钟才会写入一次S3。这会导致S3里的日志有时会滞后一些。不过为了能方便的看到日志，我们只能捏着鼻子忍了。最后，日志终究只是日志而已，为了节省空间，三十天后我们就可以自动删除日志了，这个在S3上配置也很方便。


 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19


resource &#34;aws_s3_bucket&#34; &#34;emr_log&#34; {
  bucket = &#34;${var.company_name}-${var.team_name}-emr-log-${var.environment}&#34;
  acl    = &#34;private&#34;
  tags   = local.common.tags

  lifecycle_rule {
    id      = &#34;${var.company_name}-${var.team_name}-emr-log-${var.environment}-rule&#34;
    enabled = true
    expiration {
      days = 30
    }
  }
}

resource &#34;aws_emr_cluster&#34; &#34;etl_cluster&#34; {
  ...

  log_uri          = &#34;s3n://${aws_s3_bucket.emr_log.id}/&#34;
}


"><!--[if lte IE 9]><script src=https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js></script><![endif]--><!--[if lt IE 9]><script src=https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js></script>
<script src=https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js></script><![endif]--></head><body><div id=mobile-navbar class=mobile-navbar><div class=mobile-header-logo><a href=/ class=logo>心之所向</a></div><div class=mobile-navbar-icon><span></span>
<span></span>
<span></span></div></div><nav id=mobile-menu class="mobile-menu slideout-menu"><ul class=mobile-menu-list><a href=/><li class=mobile-menu-item>主页</li></a><a href=/post/><li class=mobile-menu-item>博客</li></a><a href=/about/><li class=mobile-menu-item>关于</li></a></ul></nav><div class=container id=mobile-panel><header id=header class=header><div class=logo-wrapper><a href=/ class=logo>心之所向</a></div><nav class=site-navbar><ul id=menu class=menu><li class=menu-item><a class=menu-item-link href=/>主页</a></li><li class=menu-item><a class=menu-item-link href=/post/>博客</a></li><li class=menu-item><a class=menu-item-link href=/about/>关于</a></li></ul></nav></header><main id=main class=main><div class=content-wrapper><div id=content class=content><article class=post><header class=post-header><h1 class=post-title>在AWS上使用EMR创建一个简单的数据湖（2）</h1><div class=post-meta><span class=post-time>2021-01-26</span></div></header><div class=post-content><p>接下来，我们就可以动手创建AWS上的各种资源了。Terraform走起~</p><h2 id=创建s3存储>创建S3存储</h2><p>创建S3的代码很简单，只需要注意这么几点：</p><ul><li>S3需要一个唯一的名字。不光是在自己的AWS账号上唯一哦，因为S3的名字是所谓Global Name，需要全球唯一 =_=!</li><li>偶尔还是要有一些安全意识的，比如ACL最好设成private</li><li>存储的数据量大了，我们就要考虑成本问题了。S3大致上有三级存储，Standard/Standard_IA/Glacier，性能和价格双双依次降低。在绝大多数情况下，我们只会频繁使用近期的数据。这样，我们可以把古老的数据挪到更便宜的存储上。虽然S3已经很便宜了，但是羊毛还是能薅就薅。</li></ul><p>Terraform代码如下：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Terraform data-lang=Terraform><span class=line><span class=cl><span class=kr>resource</span> <span class=s2>&#34;aws_s3_bucket&#34;</span> <span class=s2>&#34;data&#34;</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=na>bucket</span> = <span class=s2>&#34;</span><span class=si>${</span><span class=nb>var</span><span class=p>.</span><span class=nx>company_name</span><span class=si>}</span><span class=s2>-</span><span class=si>${</span><span class=nb>var</span><span class=p>.</span><span class=nx>team_name</span><span class=si>}</span><span class=s2>-data-</span><span class=si>${</span><span class=nb>var</span><span class=p>.</span><span class=nx>environment</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>  <span class=na>acl</span>    = <span class=s2>&#34;private&#34;</span>
</span></span><span class=line><span class=cl>  <span class=na>tags</span>   = <span class=nx>local</span><span class=p>.</span><span class=nx>common</span><span class=p>.</span><span class=nx>tags</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=nx>lifecycle_rule</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=na>id</span>      = <span class=s2>&#34;</span><span class=si>${</span><span class=nb>var</span><span class=p>.</span><span class=nx>company_name</span><span class=si>}</span><span class=s2>-</span><span class=si>${</span><span class=nb>var</span><span class=p>.</span><span class=nx>team_name</span><span class=si>}</span><span class=s2>-data-</span><span class=si>${</span><span class=nb>var</span><span class=p>.</span><span class=nx>environment</span><span class=si>}</span><span class=s2>-rule&#34;</span>
</span></span><span class=line><span class=cl>    <span class=na>enabled</span> = <span class=kc>true</span>
</span></span><span class=line><span class=cl>    <span class=nx>transition</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=na>days</span>          = <span class=m>60</span>
</span></span><span class=line><span class=cl>      <span class=na>storage_class</span> = <span class=s2>&#34;STANDARD_IA&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=nx>transition</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=na>days</span>          = <span class=m>365</span>
</span></span><span class=line><span class=cl>      <span class=na>storage_class</span> = <span class=s2>&#34;GLACIER&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></td></tr></table></div></div><p>我们还可以加点别的功能（所谓“来都来了”），比如当我们给S3中写入了新的数据的时候，我们想得到一个通知。之后利用这个通知，我们就可以驱动很多事情，比如EMR上面的处理任务，或者发邮件通知同事们数据已经准备好了。这个也不难，首先创建一个SNS消息队列，然后把安全性配置好就行了。走起~</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Terraform data-lang=Terraform><span class=line><span class=cl><span class=c1>
</span></span></span><span class=line><span class=cl><span class=c1>// 创建SNS消息队列
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=kr>resource</span> <span class=s2>&#34;aws_sns_topic&#34;</span> <span class=s2>&#34;sns_s3_data_notification_queue&#34;</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=na>name</span> = <span class=s2>&#34;</span><span class=si>${</span><span class=nb>var</span><span class=p>.</span><span class=nx>team_name</span><span class=si>}</span><span class=s2>-sns-s3-notification-</span><span class=si>${</span><span class=nb>var</span><span class=p>.</span><span class=nx>environment</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>  <span class=na>tags</span> = <span class=nx>local</span><span class=p>.</span><span class=nx>common</span><span class=p>.</span><span class=nx>tags</span>
</span></span><span class=line><span class=cl><span class=p>}</span><span class=c1>
</span></span></span><span class=line><span class=cl><span class=c1>
</span></span></span><span class=line><span class=cl><span class=c1>// 设置SNS，允许S3发送消息
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=kr>data</span> <span class=s2>&#34;aws_iam_policy_document&#34;</span> <span class=s2>&#34;sns_policy_doc&#34;</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nx>statement</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=na>actions</span> = <span class=p>[</span><span class=s2>&#34;SNS:Publish&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=na>effect</span> = <span class=s2>&#34;Allow&#34;</span>
</span></span><span class=line><span class=cl>        <span class=nx>principals</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=na>type</span>        = <span class=s2>&#34;AWS&#34;</span>
</span></span><span class=line><span class=cl>            <span class=na>identifiers</span> = <span class=p>[</span><span class=s2>&#34;*&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=na>resources</span> = <span class=p>[</span><span class=s2>&#34;</span><span class=si>${</span><span class=nx>aws_sns_topic</span><span class=p>.</span><span class=nx>sns_s3_data_notification_queue</span><span class=p>.</span><span class=nx>arn</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=nx>condition</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=na>test</span>     = <span class=s2>&#34;ArnLike&#34;</span>
</span></span><span class=line><span class=cl><span class=kr>            variable</span> <span class=o>=</span> <span class=s2>&#34;aws:SourceArn&#34;</span>
</span></span><span class=line><span class=cl>            <span class=na>values</span> = <span class=p>[</span><span class=s2>&#34;</span><span class=si>${</span><span class=nx>aws_s3_bucket</span><span class=p>.</span><span class=nb>data</span><span class=p>.</span><span class=nx>arn</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=kr>
</span></span></span><span class=line><span class=cl><span class=kr>resource</span> <span class=s2>&#34;aws_sns_topic_policy&#34;</span> <span class=s2>&#34;default&#34;</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=na>arn</span> = <span class=s2>&#34;</span><span class=si>${</span><span class=nx>aws_sns_topic</span><span class=p>.</span><span class=nx>SNS_s3_notification</span><span class=p>.</span><span class=nx>arn</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>    <span class=na>policy</span> = <span class=s2>&#34;</span><span class=si>${</span><span class=nb>data</span><span class=p>.</span><span class=nx>aws_iam_policy_document</span><span class=p>.</span><span class=nx>SNS_policy_doc</span><span class=p>.</span><span class=nx>json</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl><span class=p>}</span><span class=c1>
</span></span></span><span class=line><span class=cl><span class=c1>
</span></span></span><span class=line><span class=cl><span class=c1>// 设置S3，发送ObjectCreated消息
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=kr>resource</span> <span class=s2>&#34;aws_s3_bucket_notification&#34;</span> <span class=s2>&#34;data-bucket-notification&#34;</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=na>bucket</span> = <span class=s2>&#34;</span><span class=si>${</span><span class=nx>aws_s3_bucket</span><span class=p>.</span><span class=nx>general_data</span><span class=p>.</span><span class=nx>id</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>  <span class=nx>topic</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=na>topic_arn</span> = <span class=s2>&#34;</span><span class=si>${</span><span class=nx>aws_sns_topic</span><span class=p>.</span><span class=nx>SNS_s3_notification</span><span class=p>.</span><span class=nx>arn</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>    <span class=na>events</span> = <span class=p>[</span><span class=s2>&#34;s3:ObjectCreated:*&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></td></tr></table></div></div><p>很好，从数据存储角度来说，这个S3基本够用了。</p><h2 id=创建emr集群>创建EMR集群</h2><p>在我们的计划中，所有的ETL任务都是在同一个EMR集群上运行的。创建EMR还是比较麻烦的，主要是安全性的配置非常多。这也就是为什么有很多公司提供一键部署EMR集群的服务，虽然只是在AWS上包装了一层，但还能向用户再次收费的原因，毕竟省了很多事儿啊。不过我们一步一步来，先从创建一个简单的EMR集群开始。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Terraform data-lang=Terraform><span class=line><span class=cl><span class=kr>resource</span> <span class=s2>&#34;aws_emr_cluster&#34;</span> <span class=s2>&#34;etl_cluster&#34;</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=na>name</span>          = <span class=s2>&#34;</span><span class=si>${</span><span class=nb>var</span><span class=p>.</span><span class=nx>team_name</span><span class=si>}</span><span class=s2>-etl-cluster-</span><span class=si>${</span><span class=nb>var</span><span class=p>.</span><span class=nx>environment</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>  <span class=na>tags</span>          =<span class=nb> merge</span><span class=p>(</span> <span class=nx>local</span><span class=p>.</span><span class=nx>common</span><span class=p>.</span><span class=nx>tags</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                        <span class=p>{</span>
</span></span><span class=line><span class=cl>                          <span class=na>useTag</span> = <span class=s2>&#34;etl&#34;</span>
</span></span><span class=line><span class=cl>                        <span class=p>}</span>
</span></span><span class=line><span class=cl>                        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=na>release_label</span> = <span class=s2>&#34;emr-5.30.0&#34;</span>
</span></span><span class=line><span class=cl>  <span class=na>applications</span>  = <span class=p>[</span><span class=s2>&#34;Spark&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=nx>master_instance_group</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=na>instance_type</span> = <span class=s2>&#34;m5.xlarge&#34;</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=nx>core_instance_group</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=na>instance_type</span>  = <span class=s2>&#34;m5.xlarge&#34;</span>
</span></span><span class=line><span class=cl>    <span class=na>instance_count</span> = <span class=m>5</span>
</span></span><span class=line><span class=cl>    <span class=na>name</span>           = <span class=s2>&#34;</span><span class=si>${</span><span class=nb>var</span><span class=p>.</span><span class=nx>team_name</span><span class=si>}</span><span class=s2>-etl-cluster-core-instance-group-</span><span class=si>${</span><span class=nb>var</span><span class=p>.</span><span class=nx>environment</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></td></tr></table></div></div><p>是的，就是这么简单。我们只装了一个软件，就是Spark，用来做计算。根据不同的需求，我们还可以安装Hadoop来做传统的MapReduce计算，或者Livy来做更好的Spark任务管理。具体需要装什么软件，各位看官可能比我还要熟悉，这里就不提了。我们在这个系列文章里只以Spark来举例。</p><p>运行一下这个Terraform脚本，各种关于安全性的狗屁倒灶的事情就接踵而来。首先，EMR可以理解为AWS帮我们管理一堆EC2机器。但是，EMR本身需要一定的权限来对机器进行添加、删除、监控、更改权限等等操作。这个叫做EMR服务角色（Service Role）。我们需要把这个角色创建出来，并且告诉我们的集群，使用这个角色来管理我们的集群机器。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Terraform data-lang=Terraform><span class=line><span class=cl><span class=kr>data</span> <span class=s2>&#34;aws_iam_policy_document&#34;</span> <span class=s2>&#34;emr_service_assume_role&#34;</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nx>statement</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nx>principals</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=na>type</span>        = <span class=s2>&#34;Service&#34;</span>
</span></span><span class=line><span class=cl>      <span class=na>identifiers</span> = <span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;elasticmapreduce.amazonaws.com&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;application-autoscaling.amazonaws.com&#34;</span>
</span></span><span class=line><span class=cl>      <span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=na>actions</span> = <span class=p>[</span><span class=s2>&#34;sts:AssumeRole&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=kr>
</span></span></span><span class=line><span class=cl><span class=kr>resource</span> <span class=s2>&#34;aws_iam_role&#34;</span> <span class=s2>&#34;emr_service_role&#34;</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=na>name</span>               = <span class=s2>&#34;</span><span class=si>${</span><span class=nb>var</span><span class=p>.</span><span class=nx>team_name</span><span class=si>}</span><span class=s2>-emr-service-role-</span><span class=si>${</span><span class=nb>var</span><span class=p>.</span><span class=nx>environment</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>  <span class=na>assume_role_policy</span> = <span class=nb>data</span><span class=p>.</span><span class=nx>aws_iam_policy_document</span><span class=p>.</span><span class=nx>emr_service_assume_role</span><span class=p>.</span><span class=nx>json</span>
</span></span><span class=line><span class=cl>  <span class=na>tags</span>               = <span class=nx>local</span><span class=p>.</span><span class=nx>common</span><span class=p>.</span><span class=nx>tags</span>
</span></span><span class=line><span class=cl>  <span class=na>path</span>               = <span class=s2>&#34;/</span><span class=si>${</span><span class=nb>var</span><span class=p>.</span><span class=nx>team_name</span><span class=si>}</span><span class=s2>/&#34;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=kr>
</span></span></span><span class=line><span class=cl><span class=kr>resource</span> <span class=s2>&#34;aws_iam_role_policy_attachment&#34;</span> <span class=s2>&#34;emr_service_role_policy_attachment&#34;</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=na>role</span>       = <span class=nx>aws_iam_role</span><span class=p>.</span><span class=nx>emr_service_role</span><span class=p>.</span><span class=nx>name</span>
</span></span><span class=line><span class=cl>  <span class=na>policy_arn</span> = <span class=s2>&#34;arn:aws:iam::aws:policy/service-role/AmazonElasticMapReduceRole&#34;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></td></tr></table></div></div><p>上面的这种代码如此常用，已经可以提取出来作为创建IAM角色的标准模板了，也就是先创建一个空白的角色，用AssumeRole策略告诉AWS谁可以代入这个角色。最后再把这个角色所具有的策略添加上去。这里，我们没有手动创建角色所具有的策略，而是使用了AWS自动创建的AmazonElasticMapReduceRole策略。有兴趣的人，或者公司的安全管理人员可以去看看这个策略里包含了哪些权限，保准你会感到心惊胆战，基本上能赋予的权限都包圆了。我们可不可以自己设定一个稍微弱一点的权限呢，能提升一点安全性就提升一点。答案是……不能。经过多次尝试，并且和AWS Tech Support各种亲切交流，我最终确认了，这个策略还是不要动为好。不过可以聊以自慰的是，这个角色只会被AWS自己使用，只能用人不疑了。</p><p>这样，我们就可以告诉EMR使用我们刚刚创建的IAM角色了。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Terraform data-lang=Terraform><span class=line><span class=cl><span class=kr>resource</span> <span class=s2>&#34;aws_emr_cluster&#34;</span> <span class=s2>&#34;etl_cluster&#34;</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=p>...</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=na>service_role</span>     = <span class=nx>aws_iam_role</span><span class=p>.</span><span class=nx>emr_service_role</span><span class=p>.</span><span class=nx>arn</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></td></tr></table></div></div><p>接下来，我们要配置我们的EMR集群，使得当任务较多的时候，我们的集群可以自动添加更多的机器，而当任务较少的时候，集群里的机器也会自动变少。这个过程最好越快越好，这样我们在拥有足够多的机器来完成任务的同时，也能充分省钱。小门小户的，要精打细算。这里，我们需要创建一个支持自动伸缩（Auto Scaling）的角色来供EMR使用。是的，我们要创建新的角色而不能重用之前的服务角色，因为赋予的权限是不同的。所幸我们不需要自己去研究哪些权限是必要的，因为AWS再一次自动帮我们创建了包含必要权限的策略。之后，我们需要创建一个EMR集群的自动伸缩策略，告诉AWS我们最少需要保持多少机器，最多允许多少机器（否则一个不小心，分分钟破产的节奏）。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Terraform data-lang=Terraform><span class=line><span class=cl><span class=kr>resource</span> <span class=s2>&#34;aws_iam_role&#34;</span> <span class=s2>&#34;emr_autoscaling_role&#34;</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=na>name</span>               = <span class=s2>&#34;</span><span class=si>${</span><span class=nb>var</span><span class=p>.</span><span class=nx>team_name</span><span class=si>}</span><span class=s2>-emr-autoscaling-role-</span><span class=si>${</span><span class=nb>var</span><span class=p>.</span><span class=nx>environment</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>  <span class=na>assume_role_policy</span> = <span class=nb>data</span><span class=p>.</span><span class=nx>aws_iam_policy_document</span><span class=p>.</span><span class=nx>emr_service_assume_role</span><span class=p>.</span><span class=nx>json</span>
</span></span><span class=line><span class=cl>  <span class=na>tags</span>               = <span class=nx>local</span><span class=p>.</span><span class=nx>common</span><span class=p>.</span><span class=nx>tags</span>
</span></span><span class=line><span class=cl>  <span class=na>path</span>               = <span class=s2>&#34;/</span><span class=si>${</span><span class=nb>var</span><span class=p>.</span><span class=nx>team_name</span><span class=si>}</span><span class=s2>/&#34;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=kr>
</span></span></span><span class=line><span class=cl><span class=kr>resource</span> <span class=s2>&#34;aws_iam_role_policy_attachment&#34;</span> <span class=s2>&#34;emr_autoscaling_role_policy_attachment&#34;</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=na>role</span>       = <span class=nx>aws_iam_role</span><span class=p>.</span><span class=nx>emr_autoscaling_role</span><span class=p>.</span><span class=nx>name</span>
</span></span><span class=line><span class=cl>  <span class=na>policy_arn</span> = <span class=s2>&#34;arn:aws:iam::aws:policy/service-role/AmazonElasticMapReduceforAutoScalingRole&#34;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=kr>
</span></span></span><span class=line><span class=cl><span class=kr>resource</span> <span class=s2>&#34;aws_emr_cluster&#34;</span> <span class=s2>&#34;etl_cluster&#34;</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=p>...</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=na>autoscaling_role</span> = <span class=nx>aws_iam_role</span><span class=p>.</span><span class=nx>emr_autoscaling_role</span><span class=p>.</span><span class=nx>arn</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=kr>
</span></span></span><span class=line><span class=cl><span class=kr>resource</span> <span class=s2>&#34;aws_emr_managed_scaling_policy&#34;</span> <span class=s2>&#34;emr_scaling_policy&#34;</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=na>cluster_id</span> = <span class=nx>aws_emr_cluster</span><span class=p>.</span><span class=nx>etl_cluster</span><span class=p>.</span><span class=nx>id</span>
</span></span><span class=line><span class=cl>  <span class=nx>compute_limits</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=na>unit_type</span>                       = <span class=s2>&#34;Instances&#34;</span>
</span></span><span class=line><span class=cl>    <span class=na>minimum_capacity_units</span>          = <span class=m>5</span>
</span></span><span class=line><span class=cl>    <span class=na>maximum_capacity_units</span>          = <span class=m>200</span>
</span></span><span class=line><span class=cl>    <span class=na>maximum_ondemand_capacity_units</span> = <span class=m>40</span>
</span></span><span class=line><span class=cl>    <span class=na>maximum_core_capacity_units</span>     = <span class=m>10</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></td></tr></table></div></div><p>最后，我们的EMR集群需要一个地方来存储日志。EMR可以在本机存日志，但是我们真的不想每次都冲上集群的机器上去看日志，而是想在网页界面上直接看到任务的运行状况，并且当EMR集群由于某种原因挂掉的时候（这是日志文件这辈子最重要的时刻），我们还是可以看到日志，并得知集群最后的遗言。总之，我们希望EMR集群的日志保存在一个EMR之外的地方。是的，你猜对了，S3走起。我们另外创建一个S3存储日志，并配置我们的EMR集群持续写入。由于S3只能写入一个一个完整的对象，而不能持续给对象尾部添加内容，为了避免产生大量的小对象，EMR内部会有缓存机制，默认每5分钟才会写入一次S3。这会导致S3里的日志有时会滞后一些。不过为了能方便的看到日志，我们只能捏着鼻子忍了。最后，日志终究只是日志而已，为了节省空间，三十天后我们就可以自动删除日志了，这个在S3上配置也很方便。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-Terraform data-lang=Terraform><span class=line><span class=cl><span class=kr>resource</span> <span class=s2>&#34;aws_s3_bucket&#34;</span> <span class=s2>&#34;emr_log&#34;</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=na>bucket</span> = <span class=s2>&#34;</span><span class=si>${</span><span class=nb>var</span><span class=p>.</span><span class=nx>company_name</span><span class=si>}</span><span class=s2>-</span><span class=si>${</span><span class=nb>var</span><span class=p>.</span><span class=nx>team_name</span><span class=si>}</span><span class=s2>-emr-log-</span><span class=si>${</span><span class=nb>var</span><span class=p>.</span><span class=nx>environment</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>  <span class=na>acl</span>    = <span class=s2>&#34;private&#34;</span>
</span></span><span class=line><span class=cl>  <span class=na>tags</span>   = <span class=nx>local</span><span class=p>.</span><span class=nx>common</span><span class=p>.</span><span class=nx>tags</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=nx>lifecycle_rule</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=na>id</span>      = <span class=s2>&#34;</span><span class=si>${</span><span class=nb>var</span><span class=p>.</span><span class=nx>company_name</span><span class=si>}</span><span class=s2>-</span><span class=si>${</span><span class=nb>var</span><span class=p>.</span><span class=nx>team_name</span><span class=si>}</span><span class=s2>-emr-log-</span><span class=si>${</span><span class=nb>var</span><span class=p>.</span><span class=nx>environment</span><span class=si>}</span><span class=s2>-rule&#34;</span>
</span></span><span class=line><span class=cl>    <span class=na>enabled</span> = <span class=kc>true</span>
</span></span><span class=line><span class=cl>    <span class=nx>expiration</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=na>days</span> = <span class=m>30</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=kr>
</span></span></span><span class=line><span class=cl><span class=kr>resource</span> <span class=s2>&#34;aws_emr_cluster&#34;</span> <span class=s2>&#34;etl_cluster&#34;</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=p>...</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=na>log_uri</span>          = <span class=s2>&#34;s3n://</span><span class=si>${</span><span class=nx>aws_s3_bucket</span><span class=p>.</span><span class=nx>emr_log</span><span class=p>.</span><span class=nx>id</span><span class=si>}</span><span class=s2>/&#34;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></td></tr></table></div></div></div><footer class=post-footer><nav class=post-nav><a class=prev href=/post/2021-01-28/><i class="iconfont icon-left"></i>
<span class="prev-text nav-default">AWS MSK的安全性设置</span>
<span class="prev-text nav-mobile">上一篇</span></a>
<a class=next href=/post/2021-01-24/><span class="next-text nav-default">在AWS上使用EMR创建一个简单的数据湖（1）</span>
<span class="next-text nav-mobile">下一篇</span>
<i class="iconfont icon-right"></i></a></nav></footer></article></div></div></main><footer id=footer class=footer><div class=social-links><a href=cerrorism@gmail.com class="iconfont icon-email" title=email></a>
<a href=https://linkedin.com/in/zhengguang-chen-a4a4b430 class="iconfont icon-linkedin" title=linkedin></a>
<a href=https://github.com/cerrorism class="iconfont icon-github" title=github></a>
<a href=https://www.zhihu.com/people/chen-zheng-guang class="iconfont icon-zhihu" title=zhihu></a>
<a href=https://space.bilibili.com/1614504 class="iconfont icon-bilibili" title=bilibili></a>
<a href=https://blog.cerrorism.com/index.xml type=application/rss+xml class="iconfont icon-rss" title=rss></a></div><div class=copyright><span class=power-by>由 <a class=hexo-link href=https://gohugo.io>Hugo</a> 强力驱动</span>
<span class=division>|</span>
<span class=theme-info>主题 -
<a class=theme-link href=https://github.com/olOwOlo/hugo-theme-even>Even</a></span>
<span class=copyright-year>&copy;
2020 -
2022<span class=heart><i class="iconfont icon-heart"></i></span><span>Zhengguang Chen</span></span></div></footer><div class=back-to-top id=back-to-top><i class="iconfont icon-up"></i></div></div><script src=https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin=anonymous></script>
<script type=text/javascript src=/js/main.min.4ae89da218555efa0e7093a20b92017d2e1202b66fff9fc2edf4cb8d44b44c6e.js></script>
<script src=/js/mermaid.min.js></script></body></html>
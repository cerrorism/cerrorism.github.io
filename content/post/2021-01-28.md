---
title: "AWS MSK的安全性设置"
date: 2021-01-28T14:12:35-08:00
lastmod: 2021-01-28T14:12:35-08:00
draft: false
keywords: []
description: ""
tags: []
categories: []
author: ""

# You can also close(false) or open(true) something for this content.
# P.S. comment can only be closed
comment: false
toc: false
autoCollapseToc: false
postMetaInFooter: false
hiddenFromHomePage: false
# You can also define another contentCopyright. e.g. contentCopyright: "This is another copyright."
contentCopyright: false
reward: false
mathjax: false
mathjaxEnableSingleDollar: false
mathjaxEnableAutoNumber: false

# You unlisted posts you might want not want the header or footer to show
hideHeaderAndFooter: false

# You can enable or disable out-of-date content warning for individual post.
# Comment this out to use the global config.
#enableOutdatedInfoWarning: false

flowchartDiagrams:
  enable: false
  options: ""

sequenceDiagrams: 
  enable: false
  options: ""

---

如今设计大型软件系统的时候，异步和消息队列已经成了一种时尚。不管数据量大还是小，服务设计成异步总会看起来高大上一些。不要问，问就是设计容量一个亿(小目标)。针对这种需求，AWS MSK成为了想使用Kafka作为消息队列，但又不想管理Kafka集群的公司的一个好选择。

相比AWS提供的其他消息队列服务，比如SQS、SNS、Kinesis之类，Kafka的优势是通用的API和大量的第三方文档（妈妈再也不用担心我被绑定在AWS上了）。但是Kafka的一个劣势是它目前没有和IAM很好的集成，安全性设置起来比较麻烦。

MSK的安全性分为两部分。首先是消息加密，保证了客户端只有使用适当的密钥才能解密查看接收到的信息。然后是基于证书的客户端验证，来保证只有特定的客户端才可以连接到Kafka集群。在这篇文章里，我们一步一步来配置安全的AWS MSK。

## 创建AWS MSK

首先，我们创建一个简单的MSK集群。这里，我们使用2.5.1版本，其他全默认。分配磁盘空间500G，大部分情况足够用了。不够再加，反正够便宜。

```Terraform
resource "aws_msk_cluster" "msk_cluster" {
    cluster_name = "${var.team_name}-msk-${var.environment}"
    kafka_version = "2.5.1"
    number_of_broker_nodes = "3"

    broker_node_group_info {
        instance_type = "kafka.m5.xlarge"
        ebs_volume_size = "500"
        az_distribution = "DEFAULT"
    }


    tags   = local.common.tags
}
```

如果我们只是想用一个简单的MSK集群，这样就够用了。可是，为了让这个Kafka集群可以在产品上使用，也就是所谓的“Product-Ready”，我们需要加入更多的配置，比如日志，比如监控，再比如无比重要的安全性。

首先就是监控。如果你运气好的话，公司里已经有可以和prometheus集成的监控系统了。如果没有的话，请出门左转Grafana（花点钱，花点……）。prometheus几乎要成为监控数据事实上的标准了，而AWS MSK在这方面的设置也是很简单的，暴露出来接口就好了。代码如下：

```Terraform
resource "aws_msk_cluster" "msk_cluster" {
    ...
    open_monitoring {
        prometheus {
            jmx_exporter {
                enabled_in_broker = true
            }
            node_exporter {
                enabled_in_broker = true
            }
        }
    }
}
```

接下来，我们要把日志保存下来。必要的时候，最起码要知道自己是怎么挂掉的。这里，我们把日志保存在一个S3桶里。还是老样子，30天后自动删除。如果Kafka挂掉了30天后还没人发现，导致日志没了……那它死不死的也不是很重要了。

```Terraform
resource "aws_s3_bucket" "log-bucket" {
    force_destroy = true
    bucket        = "${var.company_name}-${var.team_name}-msk-log-${var.environment}"
    acl           = "private"
    tags          = local.common.tags

    lifecycle_rule {
        id      = "${var.company_name}-${var.team_name}-msk-log-${var.environment}-rule"
        enabled = true
        expiration {
            days = 120
        }
    }
}

resource "aws_msk_cluster" "msk_cluster" {
    ...
    logging_info {
        broker_logs {
            s3 {
                enabled = true
                bucket  = aws_s3_bucket.log-bucket.id
                prefix  = "logs/msk-"
            }
        }
    }
}
```

最后，我们加入一些Kafka本身的配置，比如是否允许删除Topic啦，是否允许自动创建Topic啦。这种东西和AWS没什么关系，如有疑问，出门左转Kafka自己的文档，我们这里就不详谈了。不过为了方便，我们这里配置客户端可以自由地增删Topic。自动管理嘛，我们只需要管好Kafka集群不出问题就好了。

```Terraform
resource "aws_msk_configuration" "msk_cluster_config" {
  kafka_versions = ["2.5.1"]
  name           = "${var.team_name}-msk-config-${var.environment}"

  server_properties = <<PROPERTIES
    auto.create.topics.enable = true
    delete.topic.enable = true
    PROPERTIES
}

resource "aws_msk_cluster" "msk_cluster" {
    ...
    configuration_info {
        arn = aws_msk_configuration.msk_cluster_config.arn
        revision = aws_msk_configuration.msk_cluster_config.latest_revision
    }
}
```

## 数据安全性 - 基于KMS的数据加密

好了，开始我们的安全性表演。首先就是数据加密。我们在KMS上创建一个加密密钥，然后使用这个密钥来对数据进行加密。注意，我们的客户端需要有权限来得到这个密钥，否则当然是没法读取数据的。这一部分客户端权限的配置，我们在最后介绍客户端的时候再详细说。现在来看，我们就是用一个保存在KMS上的加密密钥来强行把Kafka的数据安全性和IAM验证捆绑起来。只要IAM是安全的，我们的客户端能正常的得到密钥，那么整个体系就能安全的运转。

```Terraform
resource "aws_kms_key" "encrypt_key" {
    description              = "KMS key for MSK"
    deletion_window_in_days  = 10
    key_usage                = "ENCRYPT_DECRYPT"
    customer_master_key_spec = "SYMMETRIC_DEFAULT"
    enable_key_rotation      = true
    tags                     = local.common.tags
}
```

请注意，首先我们开启了密钥自动更新（key_rotation）选项，也就是每隔一段时间我们就更新一下这个加密密钥。这样就算某一个密钥泄露了，也不会造成永久的伤害。KMS会保证记录下所有的历史密钥，所以不用担心密钥更新会导致服务不可用。另外，我们使用了对称加密（SYMMETRIC_DEFAULT），因为这是目前Kafka唯一支持的方式。

为了管理的方便，也便于我们在AWS网站上查看，我们给这个密钥一个别名。

```Terraform
resource "aws_kms_alias" "encrypt_key" {
    name          = "alias/${var.team_name}-msk-key-${var.environment}"
    target_key_id = aws_kms_key.encrypt_key.key_id
}
```

最后，我们告诉MSK要用这个密钥来对数据进行加密。

```Terraform
resource "aws_msk_cluster" "msk_cluster" {
    ...
    encryption_info {
        encryption_at_rest_kms_key_arn  = "${aws_kms_key.encrypt_key.arn}"
    }
}
```

搞定，加密解密都是全自动的，只要配置好权限。这个叫做服务端加密（Server Side Encryption， SSE），非常方便。

## 连接安全性 - 基于证书的客户端认证

连接的验证流程是这样的，客户端使用SSL协议连接，带上Kafka集群承认的证书，集群就会允许连接。具体的流程可以参照SSL的文档（我觉得很少有人有耐心看完那个文档，真的……）。简单来说，客户端通过证书代理（Certificate Agency）得到证书，集群通过同一个证书代理来验证证书的合法性。那么问题就简单了，让客户端和服务端都知道这个代理就好了。这不是巧了么，每个AWS的账户上都有一个根代理，图省事的话用那个就好了。如果要分离出来单独一个代理，那么就要使用AWS PCA来创建一个私有代理（Private Certificate Agency）。在一个公司中，创建代理这种一看就是“违法乱纪”的事情，一般我们不能自己动手。所以在下面的代码中，PCA是作为一个变量传进来的。

```Terraform
resource "aws_msk_cluster" "msk_cluster" {
    ...
    client_authentication {
        tls {
            certificate_authority_arns  = ["${var.acm_pca_arn}"]
        }    
    }
}
```

请注意，这里由于我们设置了TLS，那么这个集群就只允许SSL连接了，无比安全啊^_^。

在很多公司，创建证书这种事情是很麻烦的，有可能还需要和几个不同的安全组打交道。之后拿到了证书，又要小心翼翼的保存在安全的地方，因为证书相当于连接到集群所用的用户名密码，有了它就可以自由的连接到集群了。所以所有的保存密码的那一套麻烦事，都会一一的变成横列在我们面前的困难。这里，我们采取另一种方法，就是自动生成证书，并把证书放在一个S3桶里。这样客户端只要有权限从S3中下载证书，就可以连接到Kafka集群了。这样我们就把难以管理的证书问题，变成了有现成方法可依的IAM验证问题。

我们来创建用于保存证书的S3桶。为了安全起见，我们对S3中的对象进行加密，并且要求所有的存取文件操作都是加密的。加密使用的密钥我们依然使用与Kafka集群同一个密钥。我们也对对象的生命周期做一些配置，保证证书不会永久存在。

```Terraform
data "aws_iam_policy_document" "bucket_policy" {
  statement {
    effect = "Deny"
    principals {
      type        = "AWS"
      identifiers = ["*"]
    }
    actions = [
      "s3:PutObject",
    ]
    resources = [
      "arn:aws:s3:::${var.company_name}-${var.team_name}-msk-certificate-${var.environment}/*",
    ]
    condition {
      test     = "StringNotEquals"
      variable = "s3:x-amz-server-side-encryption"
      values   = ["aws:kms"]
    }
  }
  statement {
    effect = "Deny"
    principals {
      type        = "AWS"
      identifiers = ["*"]
    }
    actions = [
      "s3:PutObject",
    ]
    resources = [
      "arn:aws:s3:::${var.company_name}-${var.team_name}-msk-certificate-${var.environment}/*",
    ]
    condition {
      test     = "Null"
      variable = "s3:x-amz-server-side-encryption"
      values   = ["true"]
    }
  }
}

resource "aws_s3_bucket" "certificate-bucket" {
  force_destroy = true
  bucket        = "${var.company_name}-${var.team_name}-msk-certificate-${var.environment}"
  acl           = "private"
  tags          = local.common.tags

  server_side_encryption_configuration {
    rule {
      apply_server_side_encryption_by_default {
        kms_master_key_id = aws_kms_key.encrypt_key.arn
        sse_algorithm     = "aws:kms"
      }
    }
  }

  policy = data.aws_iam_policy_document.bucket_policy.json

  lifecycle_rule {
    id      = "${var.company_name}-${var.team_name}-msk-certificate-${var.environment}-rule"
    enabled = true

    abort_incomplete_multipart_upload_days = 3

    expiration {
      days = 732
    }
  }
}
```



## 创建用于连接的证书

在很多公司，创建证书这种事情是很麻烦的，有可能还需要和几个不同的安全组打交道。之后拿到了证书，又要小心翼翼的保存在安全的地方，因为证书相当于连接到集群所用的用户名密码，有了它就可以自由的连接到集群了。所以所有的保存密码的那一套麻烦事，都会一一的变成横列在我们面前的困难。

那么，我们能不能用IAM来管理证书的生成和更新，从而把难以管理的证书问题，变成有现成方法可依的IAM验证问题呢？当然是可以的，事在人为嘛。我们把证书管理分成这么几步：

1. 每一次客户端要连接到Kafka集群上的时候，都去一个S3桶中检查一下是否存在已有的证书，并且检查一下证书是否过期了（比如检查证书对象的某个标签）。如果证书存在并且没有过期，那么下载下来用就好了。
2. 如果证书不存在或者过期了，我们就要生成一个新的证书。这个可以使用一个单独的服务来做。
    1. 通过调用AWS证书管理服务，我们创建一个证书。证书的有效期可以设置的短一些，比如十天半个月什么的。
    2. 然后将证书放进S3里，并使用一个约定好的键。顺便可以把有效期放进S3对象的标签里。
3. 生成好了证书后，就可以回到第1步并愉快的使用刚刚生成的证书了。

最麻烦的其实是第2步，我们可以看一下代码是如何实现的。我们这里使用Kotlin来实现整个流程。我们最终的目的是创建一个KeyPair对象，并把它用特定的格式存进文件里，这样一个证书就完成了。

说起来简单，但事实上，恭喜你即将步入Java世界中最复杂的部分，JCA（Java Cryptograph Architecture）。复杂到连中文名我都懒得找了，因为整个架构真的不是很漂亮。整理流程是这样的：

1. 首先创建一个空白的KeyPair。
2. 然后生成一个证书请求，这里我们需要指明我们的服务名称是什么，还有其他的一些拥有者信息。这个证书请求会随着最后创建的证书一起，保存在我们刚刚创建的KeyPair对象里。
3. 将生成好的证书请求发给AWS的ACM-PCA服务来生成真正的证书。请注意这一步一般是异步的，也就是说请求发出去，过一段时间再去询问证书是否生成好了，之后才能下载下来证书。
4. 将下载好的证书以X.509格式保存在第1步创建的KeyPair中，再将KeyPair保存在文件中。这个就是证书文件了。
5. 最后我们将生成好的证书文件上传到S3上。

首先是第一步，创建空白KeyPair的函数。

```Kotlin
fun generateKeyPair(): KeyPair {
    val keyGen = KeyPairGenerator.getInstance("RSA")
    keyGen.initialize(1024)
    return keyGen.genKeyPair()
}
```

看起来平平无奇么，是的，这才刚开始，我们慢慢来。接下来是生成证书请求。为了简单，我们只提供一个信息，就是我们的服务名称是什么。这里我们需要服务名称作为参数，当然也需要我们之前生成的KeyPair对象。为了代码的简洁，我们使用了bouncycastle这个库（顺便推荐一下这个库，真的很好用，别看老了点，省了太多太多的事情）。

```Kotlin
fun generateCSR(x500DistinguishedName: String, keyPair: KeyPair): String {
    val p10Builder = JcaPKCS10CertificationRequestBuilder(X500Principal(x500DistinguishedName), keyPair.public)
    val signer = JcaContentSignerBuilder(signatureAlgorithm).build(keyPair.private)
    val certRequest = p10Builder.build(signer)
    return listOf(
        "-----BEGIN CERTIFICATE REQUEST-----",
        Base64.getEncoder().encodeToString(certRequest.encoded).chunked(64).joinToString("\n"),
        "-----END CERTIFICATE REQUEST-----"
    ).joinToString("\n")
}
```

接下来是生成证书了。这里我们调用AWS的PCA服务。除了函数的参数是我们上面生成的证书请求字符串，我们需要额外配置PCA的ARN，和签名的算法。

```Kotlin
val awsAcmPca: AWSACMPCA = AWSACMPCAClient.builder()
            .withRegion(region)
            .build()
val pcaArn: String = "<ARN-HERE>"
val validityDays: Int = 60
val csrSigningAlgorithm = "SHA256WITHECDSA"

fun generateNewCertificate(csrStr: String): X509Certificate {
    val issueCertificateRequest = IssueCertificateRequest().apply {
        certificateAuthorityArn = pcaArn
        csr = ByteBuffer.wrap(csrStr.toByteArray())
        signingAlgorithm = csrSigningAlgorithm
        validity = Validity().withType(ValidityPeriodType.DAYS).withValue(validityDays.toLong())
    }
    val response = awsAcmPca.issueCertificate(issueCertificateRequest)

    // wait for PCA processing cert request
    Thread.sleep(5000)
    val getCertificateResult = awsAcmPca.getCertificate(
        GetCertificateRequest()
            .withCertificateArn(response.certificateArn)
            .withCertificateAuthorityArn(pcaArn)
    )

    val cf = CertificateFactory.getInstance("X.509")
    return cf.generateCertificate(getCertificateResult.certificate.byteInputStream()) as X509Certificate
    }

```

很好，我们已经生成了证书（并且是是最常用的X509Certificate格式），那么下面的函数可以把数据存在临时文件里。为什么是临时文件呢？因为我们最终是要把证书保存在S3上的，本地存在哪里就不重要了。

```Kotlin
fun saveCertificateToFile(certificate: X509Certificate,
                          keystorePassword: String,
                          keyPair: KeyPair): File {
    val keyStoreFile = File.createTempFile("keyStore-", ".jks")

    val keyStore = KeyStore.getInstance(keystoreType)
    keyStore.load(null, null)
    keyStore.setKeyEntry(alias, keyPair.private, keystorePassword.toCharArray(), arrayOf(certificate))
    keyStoreFile.outputStream().use {
        keyStore.store(it, keystorePassword.toCharArray())
    }
    return keyStoreFile
}
```

最后，上传S3，搞定。注意，这个S3桶很重要，里面保存着的证书文件是我们Kafka集群重要的安全保证。所以，这个S3桶最好也开启SSE，保证数据进出都是加密过的。由于证书文件很小，所以我们也就不用什么多线程上传了，单个HTTP请求走起。上传的代码如下：

```Kotlin
val s3Client: AmazonS3 = AmazonS3ClientBuilder.standard()
            .withRegion(region)
            .build()
val sseKey = "<Key-ARN>"
fun putCertificate(keystore: File, serviceName: String, validityDays: Int) {
    val tags = listOf(
                    Tag("createdDate", Instant.now().toString()),
                    Tag("expiryDate", Instant.now().plus(validityDays.toLong(), ChronoUnit.DAYS).toString()))
    val objectKey = constructObjectKey(serviceName)
    val objectMetadata = ObjectMetadata().apply {
        sseAlgorithm = SSEAlgorithm.KMS.algorithm
        setHeader(Headers.SERVER_SIDE_ENCRYPTION_AWS_KMS_KEYID, sseKey)
    }
    val request = PutObjectRequest(bucketName, objectKey, keystore)
            .withMetadata(objectMetadata)
            .withTagging(ObjectTagging(tags))

    s3Client.putObject(request)
}
```

## 证书生成所需要的IAM角色

我们来看看要生成证书，我们需要什么许可。

- 首先当然是S3的存取对象了，当然还有一些辅助的操作，比如检索对象，给对象加标签等等。
- 然后是KEM相关的存取密钥的操作，这个主要是为了S3中文件的加密。
- 最后是ACM PCA的生成证书和获取证书两个操作

```Terraform
data "aws_iam_policy_document" "generate-cert-policy-doc" {
  statement {
    actions = [
      "s3:GetObject",
      "s3:PutObject",
      "s3:ListBucket",
      "s3:DeleteObject",
      "s3:ListBucketMultipartUploads",
      "s3:AbortMultipartUpload",
      "s3:PutObjectTagging",
    ]
    resources = [
      aws_s3_bucket.certificate-bucket.arn,
      "${aws_s3_bucket.certificate-bucket.arn}/*",
    ]
  }

  statement {
    actions = [
      "s3:GetBucketLocation",
      "s3:ListAllMyBuckets",
    ]
    resources = [
      "*",
    ]
  }

  statement {
    actions = [
      "kms:GenerateDataKey*",
      "kms:Encrypt",
      "kms:Decrypt",
      "kms:ReEncrypt*",
      "kms:DescribeKey",
    ]
    resources = [
      aws_kms_key.encrypt_key.arn,
    ]
  }

  statement {
    actions = [
      "acm-pca:IssueCertificate",
      "acm-pca:GetCertificate"
    ]
    resources = [
      "${var.acm_pca_arn}"
    ]
  }
}
```

至于客户端需要的权限就简单了，只需要S3的读取权限和KMS相关权限就好了。

```Terraform
data "aws_iam_policy_document" "generate-cert-policy-doc" {
  statement {
    actions = [
      "s3:GetObject",
      "s3:ListBucket",
    ]
    resources = [
      aws_s3_bucket.certificate-bucket.arn,
      "${aws_s3_bucket.certificate-bucket.arn}/*",
    ]
  }

  statement {
    actions = [
      "s3:GetBucketLocation",
      "s3:ListAllMyBuckets",
    ]
    resources = [
      "*",
    ]
  }

  statement {
    actions = [
      "kms:GenerateDataKey*",
      "kms:Encrypt",
      "kms:Decrypt",
      "kms:ReEncrypt*",
      "kms:DescribeKey",
    ]
    resources = [
      aws_kms_key.encrypt_key.arn,
    ]
  }
}
```

## 总结

好了，到此你就拥有了一个比较安全的Kafka集群了。要想进一步提升安全性，就要在网络上下功夫了，比如我们现在的kafka集群是在公网的，我们可以把它移动到我们自己的子网中，并设置适当的安全组。比如这样：

```Terraform
resource "aws_msk_cluster" "msk_cluster" {
    ...
    broker_node_group_info {
        ...
        client_subnets = ["<subnet-1>", "<subnet-2>", "<subnet-3>"]
        security_groups = ["<security-group-1>", "<security-group-2>"]
        ...
    }
}
```

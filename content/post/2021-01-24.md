---
title: "在AWS上使用EMR创建一个简单的数据湖（1）"
date: 2021-01-24T08:47:51-08:00
lastmod: 2021-01-24T08:47:51-08:00
draft: false
keywords: []
description: ""
tags: []
categories: []
author: ""

# You can also close(false) or open(true) something for this content.
# P.S. comment can only be closed
comment: false
toc: false
autoCollapseToc: false
postMetaInFooter: false
hiddenFromHomePage: false
# You can also define another contentCopyright. e.g. contentCopyright: "This is another copyright."
contentCopyright: false
reward: false
mathjax: false
mathjaxEnableSingleDollar: false
mathjaxEnableAutoNumber: false

# You unlisted posts you might want not want the header or footer to show
hideHeaderAndFooter: false

# You can enable or disable out-of-date content warning for individual post.
# Comment this out to use the global config.
#enableOutdatedInfoWarning: false

flowchartDiagrams:
  enable: false
  options: ""

sequenceDiagrams: 
  enable: false
  options: ""

---

数据湖（Data Lake）一直以来都比较火，尤其是越来越多的公司开始产生单机搞不定的数据量，数据湖成为了一个必要的基础设施。现在市面上有很多公司提供数据湖服务，比如Databricks，Snowflake，Cloudera等等。只要买了服务，部署消费一条龙，基本上不需要额外的操心（除了DevOps组的那些倒霉蛋们……）。但是，如果公司已经开始使用AWS了，在简单的使用场景下，也没必要给两个不同的公司交钱，而是使用AWS自己搭建一个简单的数据湖来自用。

## 设计思路

前人踩坑踩出来的一个宝贵经验，是“数据存储和计算平台分离”。很多计算平台会自带一个“原生”的存储，比如Spark对HDFS的支持很好（其实就是使用了Hadoop FileSystem的接口），Redshift也有自己的数据库。但是，你永远也不知道未来数据查询的需求会有怎么样的变化，而各种计算平台其实都是为某一种特定的计算做优化的。所以，数据和计算解耦合，我们可以用各种不同的计算平台来做它们专精的事情。另一个重要的原因是，随着数据量越来越大，数据的来源和形式也越来越多样。有的数据就是适合用纯文本来保存（比如log），有的数据就是适合保持它的结构化（比如数据库快照），而为了实时性，我们有的时候也会直接查询数据库。这样，通过数据和计算解耦，我们也可以让数据存储变得更灵活。回到AWS提供的各种服务，我们可以大致的将架构描述为：数据保存在S3里，通过Glue提供元数据，最后计算平台可以使用EMR，Athena，Notebook，或者Redshift。

### 存储层：S3

为什么选择S3呢？便宜啊。几个TB的数据都不是事儿。当然，如果使用的不好的话，S3也会坑的人哭爹喊娘的。首先需要理解的是，正如它的名字（Simple Storage Service，简单存储服务）所说，S3是一个简单的键值-对象存储，不提供很多数据库或者文件系统所拥有的功能。所幸，我们绝大部分时间也只是需要一个简单存储而已。但还是有几点需要在使用中注意的。

* 不要存储大量的小对象。当一个键值前缀下有上百万的小对象的时候，读取速度会异常酸爽。这是因为每读取一个小对象，客户端都会发送一个HTTP请求，而过多的请求会严重的拖慢服务的速度。而且，当我们需要读取一个目录中的所有文件时，单单一个list操作可能就要花费非常多的时间。
* 关注数据读-写的一致性。S3不是一个文件系统，写入S3这个操作是“最终一致”的。也就是说，当我们写入一个文件，这时使用list操作，写入的文件不一定会立刻出现。（备注：这一条在2021年初的时候过时了，恭喜你，需要少关注一个大坑，因为[AWS帮我们填上了](https://aws.amazon.com/s3/consistency/)。）
* 善用键值来创建目录结构，但键值真的就只是键值。S3非常贴心的把键值模拟成文件的完整路径，并且在前端用目录的形式显示给我们看。比如如果对象的键值是"a/b/c/d.txt"，那么前端显示的时候我们会看到a、b、c三个嵌套的目录。我们也可以用前缀搜索来模拟一些目录的操作，比如列表、删除。但是，模拟毕竟只是模拟，我们没有办法给目录添加各种属性，或者整体的移动操作，因为在底层存储中，目录这个概念并不存在。所有的操作都会最终转换为对单个对象的操作。一不小心，性能就会异常酸爽。

### 元数据层：Glue

S3存储虽然很容易使用，但是在逻辑层面上，它只是一个对象存储服务，几乎没有元数据，可以认为是一个个纯的二进制对象。但是，对于计算和查询而言，对象内部的结构也是很重要的，比如CSV文件里每一列的名字，列存储格式里每一个域的数据类型，都是需要一个地方来保存的。AWS提供了Glue来存储元数据，也就是S3对象的内部结构，从而暴露出一个类似于数据库的接口，使得我们可以用SQL来查询数据。值得注意的是，Glue也可以直接连上数据库，抓取数据库的元数据。这样一来，对于异构的存储（S3和各种数据库），我们也可以联合查询了。

### 计算层：EMR、Athena、Redshift

EMR是AWS提供的大数据计算集群。我们只要在创建EMR集群时声明我们需要Spark计算平台，EMR就会自动给我们安装上Spark和一系列的相关组件，让我们能够快速的开始使用，而不需要担心集群维护问题。另外，一旦元数据保存在Glue里，那么使用Athena和Redshift就变成了一个“开箱即用”的操作。

## 实现步骤

遵循架构即代码（Infrastructure As Code）的方式，这里我们使用Terraform代码来创建所有上面提到的资源。一个个资源会首先被创建出来，然后我们会配置它们，使得这些资源组成一个完整的数据湖。最后，我们会用大量的精力来保证整个体系的安全性。这样做的方便之处在于，如果在一些场景下我们不关注安全性，那么这个架构中一大半的内容可以被扔掉（众黑客：点头，点头……）。

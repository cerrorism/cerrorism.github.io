---
title: "在AWS上使用EMR创建一个简单的数据湖（2）"
date: 2021-01-26T10:46:27-08:00
lastmod: 2021-01-26T10:46:27-08:00
draft: false
keywords: []
description: ""
tags: []
categories: []
author: ""

# You can also close(false) or open(true) something for this content.
# P.S. comment can only be closed
comment: false
toc: false
autoCollapseToc: false
postMetaInFooter: false
hiddenFromHomePage: false
# You can also define another contentCopyright. e.g. contentCopyright: "This is another copyright."
contentCopyright: false
reward: false
mathjax: false
mathjaxEnableSingleDollar: false
mathjaxEnableAutoNumber: false

# You unlisted posts you might want not want the header or footer to show
hideHeaderAndFooter: false

# You can enable or disable out-of-date content warning for individual post.
# Comment this out to use the global config.
#enableOutdatedInfoWarning: false

flowchartDiagrams:
  enable: false
  options: ""

sequenceDiagrams: 
  enable: false
  options: ""

---

接下来，我们就可以动手创建AWS上的各种资源了。Terraform走起~

## 创建S3存储

创建S3的代码很简单，只需要注意这么几点：

- S3需要一个唯一的名字。不光是在自己的AWS账号上唯一哦，因为S3的名字是所谓Global Name，需要全球唯一 =_=!
- 偶尔还是要有一些安全意识的，比如ACL最好设成private
- 存储的数据量大了，我们就要考虑成本问题了。S3大致上有三级存储，Standard/Standard_IA/Glacier，性能和价格双双依次降低。在绝大多数情况下，我们只会频繁使用近期的数据。这样，我们可以把古老的数据挪到更便宜的存储上。虽然S3已经很便宜了，但是羊毛还是能薅就薅。

Terraform代码如下：

```Terraform
resource "aws_s3_bucket" "data" {
  bucket = "${var.company_name}-${var.team_name}-data-${var.environment}"
  acl    = "private"
  tags   = local.common.tags

  lifecycle_rule {
    id      = "${var.company_name}-${var.team_name}-data-${var.environment}-rule"
    enabled = true
    transition {
      days          = 60
      storage_class = "STANDARD_IA"
    }
    transition {
      days          = 365
      storage_class = "GLACIER"
    }
  }
}
```

我们还可以加点别的功能（所谓“来都来了”），比如当我们给S3中写入了新的数据的时候，我们想得到一个通知。之后利用这个通知，我们就可以驱动很多事情，比如EMR上面的处理任务，或者发邮件通知同事们数据已经准备好了。这个也不难，首先创建一个SNS消息队列，然后把安全性配置好就行了。走起~

```Terraform

// 创建SNS消息队列
resource "aws_sns_topic" "sns_s3_data_notification_queue" {
  name = "${var.team_name}-sns-s3-notification-${var.environment}"
  tags = local.common.tags
}

// 设置SNS，允许S3发送消息
data "aws_iam_policy_document" "sns_policy_doc" {
    statement {
        actions = ["SNS:Publish"]
        effect = "Allow"
        principals {
            type        = "AWS"
            identifiers = ["*"]
        }
        resources = ["${aws_sns_topic.sns_s3_data_notification_queue.arn}"]
        condition {
            test     = "ArnLike"
            variable = "aws:SourceArn"
            values = ["${aws_s3_bucket.data.arn}"]
        }
    }
}

resource "aws_sns_topic_policy" "default" {
    arn = "${aws_sns_topic.SNS_s3_notification.arn}"
    policy = "${data.aws_iam_policy_document.SNS_policy_doc.json}"
}

// 设置S3，发送ObjectCreated消息
resource "aws_s3_bucket_notification" "data-bucket-notification" {
  bucket = "${aws_s3_bucket.general_data.id}"
  topic {
    topic_arn = "${aws_sns_topic.SNS_s3_notification.arn}"
    events = ["s3:ObjectCreated:*"]
  }
}

```

很好，从数据存储角度来说，这个S3基本够用了。

## 创建EMR集群

在我们的计划中，所有的ETL任务都是在同一个EMR集群上运行的。创建EMR还是比较麻烦的，主要是安全性的配置非常多。这也就是为什么有很多公司提供一键部署EMR集群的服务，虽然只是在AWS上包装了一层，但还能向用户再次收费的原因，毕竟省了很多事儿啊。不过我们一步一步来，先从创建一个简单的EMR集群开始。

```Terraform
resource "aws_emr_cluster" "etl_cluster" {
  name          = "${var.team_name}-etl-cluster-${var.environment}"
  tags          = merge( local.common.tags,
                        {
                          useTag = "etl"
                        }
                        )

  release_label = "emr-5.30.0"
  applications  = ["Spark"]

  master_instance_group {
    instance_type = "m5.xlarge"
  }

  core_instance_group {
    instance_type  = "m5.xlarge"
    instance_count = 5
    name           = "${var.team_name}-etl-cluster-core-instance-group-${var.environment}"
  }
}
```

是的，就是这么简单。我们只装了一个软件，就是Spark，用来做计算。根据不同的需求，我们还可以安装Hadoop来做传统的MapReduce计算，或者Livy来做更好的Spark任务管理。具体需要装什么软件，各位看官可能比我还要熟悉，这里就不提了。我们在这个系列文章里只以Spark来举例。

运行一下这个Terraform脚本，各种关于安全性的狗屁倒灶的事情就接踵而来。首先，EMR可以理解为AWS帮我们管理一堆EC2机器。但是，EMR本身需要一定的权限来对机器进行添加、删除、监控、更改权限等等操作。这个叫做EMR服务角色（Service Role）。我们需要把这个角色创建出来，并且告诉我们的集群，使用这个角色来管理我们的集群机器。

```Terraform
data "aws_iam_policy_document" "emr_service_assume_role" {
  statement {
    principals {
      type        = "Service"
      identifiers = [
        "elasticmapreduce.amazonaws.com",
        "application-autoscaling.amazonaws.com"
      ]
    }
    actions = ["sts:AssumeRole"]
  }
}

resource "aws_iam_role" "emr_service_role" {
  name               = "${var.team_name}-emr-service-role-${var.environment}"
  assume_role_policy = data.aws_iam_policy_document.emr_service_assume_role.json
  tags               = local.common.tags
  path               = "/${var.team_name}/"
}

resource "aws_iam_role_policy_attachment" "emr_service_role_policy_attachment" {
  role       = aws_iam_role.emr_service_role.name
  policy_arn = "arn:aws:iam::aws:policy/service-role/AmazonElasticMapReduceRole"
}
```

上面的这种代码如此常用，已经可以提取出来作为创建IAM角色的标准模板了，也就是先创建一个空白的角色，用AssumeRole策略告诉AWS谁可以代入这个角色。最后再把这个角色所具有的策略添加上去。这里，我们没有手动创建角色所具有的策略，而是使用了AWS自动创建的AmazonElasticMapReduceRole策略。有兴趣的人，或者公司的安全管理人员可以去看看这个策略里包含了哪些权限，保准你会感到心惊胆战，基本上能赋予的权限都包圆了。我们可不可以自己设定一个稍微弱一点的权限呢，能提升一点安全性就提升一点。答案是……不能。经过多次尝试，并且和AWS Tech Support各种亲切交流，我最终确认了，这个策略还是不要动为好。不过可以聊以自慰的是，这个角色只会被AWS自己使用，只能用人不疑了。

这样，我们就可以告诉EMR使用我们刚刚创建的IAM角色了。

```Terraform
resource "aws_emr_cluster" "etl_cluster" {
  ...

  service_role     = aws_iam_role.emr_service_role.arn
}
```

接下来，我们要配置我们的EMR集群，使得当任务较多的时候，我们的集群可以自动添加更多的机器，而当任务较少的时候，集群里的机器也会自动变少。这个过程最好越快越好，这样我们在拥有足够多的机器来完成任务的同时，也能充分省钱。小门小户的，要精打细算。这里，我们需要创建一个支持自动伸缩（Auto Scaling）的角色来供EMR使用。是的，我们要创建新的角色而不能重用之前的服务角色，因为赋予的权限是不同的。所幸我们不需要自己去研究哪些权限是必要的，因为AWS再一次自动帮我们创建了包含必要权限的策略。之后，我们需要创建一个EMR集群的自动伸缩策略，告诉AWS我们最少需要保持多少机器，最多允许多少机器（否则一个不小心，分分钟破产的节奏）。

```Terraform
resource "aws_iam_role" "emr_autoscaling_role" {
  name               = "${var.team_name}-emr-autoscaling-role-${var.environment}"
  assume_role_policy = data.aws_iam_policy_document.emr_service_assume_role.json
  tags               = local.common.tags
  path               = "/${var.team_name}/"
}

resource "aws_iam_role_policy_attachment" "emr_autoscaling_role_policy_attachment" {
  role       = aws_iam_role.emr_autoscaling_role.name
  policy_arn = "arn:aws:iam::aws:policy/service-role/AmazonElasticMapReduceforAutoScalingRole"
}

resource "aws_emr_cluster" "etl_cluster" {
  ...

  autoscaling_role = aws_iam_role.emr_autoscaling_role.arn
}

resource "aws_emr_managed_scaling_policy" "emr_scaling_policy" {
  cluster_id = aws_emr_cluster.etl_cluster.id
  compute_limits {
    unit_type                       = "Instances"
    minimum_capacity_units          = 5
    maximum_capacity_units          = 200
    maximum_ondemand_capacity_units = 40
    maximum_core_capacity_units     = 10
  }
}

```

最后，我们的EMR集群需要一个地方来存储日志。EMR可以在本机存日志，但是我们真的不想每次都冲上集群的机器上去看日志，而是想在网页界面上直接看到任务的运行状况，并且当EMR集群由于某种原因挂掉的时候（这是日志文件这辈子最重要的时刻），我们还是可以看到日志，并得知集群最后的遗言。总之，我们希望EMR集群的日志保存在一个EMR之外的地方。是的，你猜对了，S3走起。我们另外创建一个S3存储日志，并配置我们的EMR集群持续写入。由于S3只能写入一个一个完整的对象，而不能持续给对象尾部添加内容，为了避免产生大量的小对象，EMR内部会有缓存机制，默认每5分钟才会写入一次S3。这会导致S3里的日志有时会滞后一些。不过为了能方便的看到日志，我们只能捏着鼻子忍了。最后，日志终究只是日志而已，为了节省空间，三十天后我们就可以自动删除日志了，这个在S3上配置也很方便。

```Terraform
resource "aws_s3_bucket" "emr_log" {
  bucket = "${var.company_name}-${var.team_name}-emr-log-${var.environment}"
  acl    = "private"
  tags   = local.common.tags

  lifecycle_rule {
    id      = "${var.company_name}-${var.team_name}-emr-log-${var.environment}-rule"
    enabled = true
    expiration {
      days = 30
    }
  }
}

resource "aws_emr_cluster" "etl_cluster" {
  ...

  log_uri          = "s3n://${aws_s3_bucket.emr_log.id}/"
}
```

<!--more-->
